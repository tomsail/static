{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76d2a5e",
   "metadata": {},
   "source": [
    "# Tidal Analysis Comparison: UTide vs PyTides\n",
    "\n",
    "We'll look into this notebook the ways of separating: \n",
    " * the **storm surge** (the meteorologically-driven component) \n",
    " * from the **astronomical tide** (the predictable gravitational component). \n",
    "\n",
    "\n",
    "## Study Location\n",
    "\n",
    "We've chosen **Roscoff, France** as our test case - with some of the largest tidal ranges in Europe (up to 9 meters).\n",
    "from the IOC database, extracted using [`searvey`](https://github.com/seareport/seareport_models), station `rosc`\n",
    "\n",
    "## The data and tools compared: \n",
    "\n",
    "We'll evaluate the following libraries for the (de)tide analysis:\n",
    "\n",
    "1. **[`UTide`](https://github.com/wesleybowman/UTide)** - Python version of the MatLab software\n",
    "2. **[`pytides2`](https://github.com/sahitono/pytides)** - fork from the official repository, working for new versions of python\n",
    "3.  **`FES2022`**: we use this model as a reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_section",
   "metadata": {},
   "source": [
    "## 0. Setting up functions, tools and data\n",
    "\n",
    "First, let's import the libraries we'll need. Each serves a specific purpose in our tidal detective work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15defa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyfes\n",
    "import searvey\n",
    "import utide\n",
    "import xarray as xr\n",
    "\n",
    "from pytides2.tide import Tide\n",
    "\n",
    "import ioc_cleanup as C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_section",
   "metadata": {},
   "source": [
    "We define the `FES_CONSTITUENTS` - these are the tidal components included in the FES 2022 model, representing the most important tidal harmonics globally.\n",
    "\n",
    "We just reordered the consituent according to their frequencies and importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c393c",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eda838",
   "metadata": {},
   "outputs": [],
   "source": [
    "UTIDE_OPTS = {\n",
    "    \"constit\": \"auto\", \n",
    "    \"method\": \"ols\", \n",
    "    \"order_constit\": \"frequency\",\n",
    "    \"Rayleigh_min\": 0.97,  # High threshold for constituent resolution\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "FES_CONSTITUENTS = [\n",
    "    \"M2\", \"S2\", \"N2\", \"K2\", \"2N2\", \"L2\", \"T2\", \"R2\", \"NU2\", \"MU2\", \"EPS2\", \"LAMBDA2\", # Semi-diurnal (twice daily)\n",
    "    \"K1\", \"O1\", \"P1\", \"Q1\", \"J1\", \"S1\", # Diurnal (once daily)\n",
    "    \"MF\", \"MM\", \"MSF\", \"SA\", \"SSA\", \"MSQM\", \"MTM\", # Long period (fortnightly to annual)\n",
    "    \"M4\", \"MS4\", \"M6\", \"MN4\", \"N4\", \"S4\", \"M8\", \"M3\", \"MKS2\" # Short period (higher harmonics)\n",
    "]\n",
    "\n",
    "DATA_FOLDER = \"data\"\n",
    "\n",
    "# for FES time series reconstruction\n",
    "START = np.datetime64('2022-01-01T00:00:00')\n",
    "END = np.datetime64(\"2022-04-01T00:00:00\")\n",
    "STEP = np.timedelta64(20, \"m\")\n",
    "DATES = np.arange(START, END+STEP, STEP)\n",
    "\n",
    "FES_M2 = xr.open_dataset(\"/home/tomsail/work/FES/load_tide/m2_fes2022.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functions_section",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee3c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_availability(series: pd.Series, freq=\"60min\") -> float:\n",
    "    resampled = series.resample(freq).mean()\n",
    "    data_avail_ratio = 1 - resampled.isna().sum() / len(resampled)\n",
    "    return float(data_avail_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db31c22",
   "metadata": {},
   "source": [
    "### Utide wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utide_get_coefs(ts: pd.Series, lat: float, resample: int = None)-> dict: \n",
    "    UTIDE_OPTS[\"lat\"] = lat\n",
    "    if resample is not None:\n",
    "        ts = ts.resample(f\"{resample}min\").mean()\n",
    "        ts = ts.shift(freq=f\"{resample / 2}min\")  # Center the resampled points\n",
    "    return utide.solve(ts.index, ts, **UTIDE_OPTS)\n",
    "\n",
    "\n",
    "def utide_surge(ts: pd.Series, lat: float, resample: int = None)-> pd.Series: \n",
    "    ts0 = ts.copy()\n",
    "    coef = utide_get_coefs(ts, lat, resample)\n",
    "    tidal = utide.reconstruct(ts0.index, coef, verbose = UTIDE_OPTS[\"verbose\"])\n",
    "    return pd.Series(data=ts0.values - tidal.h, index = ts0.index)\n",
    "\n",
    "\n",
    "def utide_to_df(utide_coef: utide.utilities.Bunch) -> pd.DataFrame:\n",
    "    return pd.DataFrame({ \n",
    "        \"amplitude\": utide_coef[\"A\"],\n",
    "        \"phase\": utide_coef[\"g\"],\n",
    "        \"amplitude_CI\": utide_coef[\"A_ci\"],\n",
    "        \"phase_CI\": utide_coef[\"g_ci\"]\n",
    "    }, index=utide_coef[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800891bd",
   "metadata": {},
   "source": [
    "### pytides wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d320d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytide_get_coefs(ts: pd.Series, resample: int = None) -> dict:\n",
    "    if resample is not None:\n",
    "        ts = ts.resample(f\"{resample}min\").mean()\n",
    "        ts = ts.shift(freq=f\"{resample / 2}min\")  # Center the resampled points\n",
    "    ts = ts.dropna()\n",
    "    return Tide.decompose(ts, ts.index.to_pydatetime())[0]\n",
    "\n",
    "\n",
    "def pytides_surge(ts: pd.Series, resample: int = None)-> pd.Series:\n",
    "    ts0 = ts.copy()\n",
    "    tide = pytide_get_coefs(ts, resample)\n",
    "    t0 = ts.index.to_pydatetime()[0]\n",
    "    hours = (ts.index - ts.index[0]).total_seconds()/3600\n",
    "    times = Tide._times(t0, hours)\n",
    "    return pd.Series(ts0.values - tide.at(times), index=ts0.index)\n",
    "\n",
    "def pytides_to_df(pytides_tide: Tide)-> pd.DataFrame:\n",
    "    constituent_names = [c.name.upper() for c in pytides_tide.model['constituent']]\n",
    "    return pd.DataFrame(pytides_tide.model, index=constituent_names).drop('constituent', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf691b",
   "metadata": {},
   "source": [
    "### FES / pyfes wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fes_yaml(path):\n",
    "    if os.path.exists(path):\n",
    "        return path\n",
    "    else:\n",
    "        raise ValueError(f\"FES Yaml not found in {path}\")\n",
    "\n",
    "def get_pyfes_cfg(yaml_file):\n",
    "    cfg = pyfes.load_config(load_fes_yaml(yaml_file))\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def reduce_coef_to_fes(df: pd.DataFrame, cnst: list, verbose: bool = False):\n",
    "    res = pd.DataFrame(0.0, index=cnst, columns=df.columns)\n",
    "    common_constituents = df.index.intersection(cnst)\n",
    "    res.loc[common_constituents] = df.loc[common_constituents]\n",
    "    \n",
    "    not_in_fes_df = df[~df.index.isin(cnst)]\n",
    "    not_in_fes = not_in_fes_df.index.tolist()\n",
    "    not_in_fes_amps = not_in_fes_df[\"amplitude\"].round(3).tolist()\n",
    "    missing_fes = set(cnst) - set(df.index)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Constituents found but not in FES: {not_in_fes}\")\n",
    "        print(f\"Their amplitudes: {not_in_fes_amps}\")\n",
    "        if missing_fes:\n",
    "            print(f\"FES constituents missing from analysis (set to 0): {sorted(missing_fes)}\")\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_constituent_name(constituent_enum):\n",
    "    name = constituent_enum.name\n",
    "    if name.startswith('k'):\n",
    "        name = name[1:].upper()\n",
    "    return name\n",
    "\n",
    "\n",
    "def get_constituents_fes(cfg, lon, lat):\n",
    "    tide_dict = cfg['tide'].interpolate([lon], [lat])[0]\n",
    "    result = {}\n",
    "    for constituent, value_array in tide_dict.items():\n",
    "        value = value_array[0]\n",
    "        amplitude = np.abs(value)\n",
    "        phase = np.mod(np.rad2deg(np.angle(value)), 360)\n",
    "        name = get_constituent_name(constituent)\n",
    "        result[name] = {\n",
    "            'amplitude': amplitude/100,\n",
    "            'phase': phase\n",
    "        }\n",
    "    return pd.DataFrame(result).T\n",
    "\n",
    "\n",
    "def fes_reconstruct(lon, lat, dates, cfg, num_threads=1):\n",
    "    lons = np.full(dates.shape, lon)\n",
    "    lats = np.full(dates.shape, lat)\n",
    "    tide, lp, qc = pyfes.evaluate_tide(cfg['tide'], dates, lons, lats, num_threads=num_threads)\n",
    "    load, load_lp, qc_lp = pyfes.evaluate_tide(cfg['radial'], dates, lons, lats, num_threads=num_threads)\n",
    "    geocentric_tide = tide + load + lp \n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"tide\": tide,\n",
    "            \"lp\": lp,\n",
    "            \"qc\": qc,\n",
    "            \"load\": load,\n",
    "            \"load_lp\": load_lp,\n",
    "            \"qc_lp\": qc_lp,\n",
    "            \"geocentric\": geocentric_tide,\n",
    "        },\n",
    "        index=dates,\n",
    "    )\n",
    "    df.attrs[\"lon\"] = lon\n",
    "    df.attrs[\"lat\"] = lat\n",
    "    return df[\"geocentric\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f6fba",
   "metadata": {},
   "source": [
    "### Comparison wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efe1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_on_obs(sim, obs):\n",
    "    obs = pd.Series(obs, name=\"obs\")\n",
    "    sim = pd.Series(sim, name=\"sim\")\n",
    "    df = pd.merge(sim, obs, left_index=True, right_index=True, how=\"outer\")\n",
    "    df[\"sim\"] = df[\"sim\"].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "    df = df.dropna(subset=[\"obs\"])\n",
    "    sim_ = df[\"sim\"].drop_duplicates()\n",
    "    obs_ = df[\"obs\"].drop_duplicates()\n",
    "    return sim_, obs_\n",
    "\n",
    "\n",
    "def compute_score(corr: float, rss: float) -> float:\n",
    "    return np.max([0, corr]) * (1 - np.min([rss, 1]))\n",
    "\n",
    "def concat_tides_constituents(dict_tides):\n",
    "    multi_df = pd.concat(dict_tides)\n",
    "    multi_df.index.names = ['method', 'constituent']\n",
    "    multi_df = multi_df.swaplevel().sort_index()\n",
    "\n",
    "    available_constituents = multi_df.index.get_level_values('constituent').unique()\n",
    "    filtered_order = [c for c in FES_CONSTITUENTS if c in available_constituents][::-1]\n",
    "    return  multi_df.reindex(filtered_order, level='constituent')\n",
    "\n",
    "def get_tidal_ts(station, ioc_df, fes_cfg, rsp = 20):\n",
    "    _lon = ioc_df[ioc_df.ioc_code == station].lon.values[0]\n",
    "    _lat = ioc_df[ioc_df.ioc_code == station].lat.values[0]\n",
    "    obs_file = glob.glob(f\"data/{station}_*.parquet\")[0]\n",
    "    ts = pd.read_parquet(obs_file)\n",
    "    ts = ts[ts.columns[0]]\n",
    "    # constituents\n",
    "    ut = utide_get_coefs(ts, _lat, resample=rsp)\n",
    "    utide_reduced_coef = reduce_coef_to_fes(utide_to_df(ut), FES_CONSTITUENTS)\n",
    "    pt = pytide_get_coefs(ts, rsp)\n",
    "    pytides_reduced_coef = reduce_coef_to_fes(pytides_to_df(pt), FES_CONSTITUENTS)\n",
    "    fes_df = get_constituents_fes(fes_cfg, _lon, _lat)\n",
    "    tide_ = concat_tides_constituents({\n",
    "        \"fes\":fes_df, \n",
    "        \"utide\":utide_reduced_coef, \n",
    "        \"pytides\": pytides_reduced_coef\n",
    "    })\n",
    "    # time domain\n",
    "    ts_fes = fes_reconstruct(lon=_lon, lat=_lat, dates=DATES, cfg=fes_cfg)\n",
    "    ts_fes_obs, _ = sim_on_obs(ts_fes, ts.loc[START:END])\n",
    "    df_obs_fes = pd.concat({\n",
    "        \"fes\": ts_fes_obs/100, \n",
    "        \"obs\": ts.loc[START: END], \n",
    "        }, axis=1)\n",
    "    return tide_, df_obs_fes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "station_setup",
   "metadata": {},
   "source": [
    "study site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21592138",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"rosc\"\n",
    "sensor = \"rad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_fetch",
   "metadata": {},
   "source": [
    "get 25 years of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = searvey.fetch_ioc_station( \n",
    "    station, \n",
    "    \"2000-01-01\", \n",
    "    pd.Timestamp.now()\n",
    ")\n",
    "raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "station_info",
   "metadata": {},
   "source": [
    "Station Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb90f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get station metadata\n",
    "ioc_df = searvey.get_ioc_stations()\n",
    "_lat = ioc_df[ioc_df.ioc_code == station].lat.values[0]\n",
    "\n",
    "station_info = ioc_df[ioc_df.ioc_code == station]\n",
    "print(f\"Station: {station_info['location'].values[0]}\")\n",
    "print(f\"Latitude: {_lat:.4f}°N\")\n",
    "print(f\"Longitude: {station_info['lon'].values[0]:.4f}°E\")\n",
    "print(f\"Country: {station_info['country'].values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_cleaning",
   "metadata": {},
   "source": [
    "let's clean the data, using [ioc_cleanup](https://github.com/seareport/ioc_cleanup/tree/ioc_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p transformations\n",
    "import requests\n",
    "response = requests.get(f'https://raw.githubusercontent.com/seareport/ioc_cleanup/refs/heads/ioc_2024/transformations/{station}_{sensor}.json')\n",
    "with open(f'transformations/{station}_{sensor}.json', 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transformation_preview",
   "metadata": {},
   "source": [
    "here's a snapshot at the cleaning trasnformation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c76ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -20 \"transformations/{station}_{sensor}.json\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apply_qc",
   "metadata": {},
   "source": [
    "Now let's apply these transformations to clean our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and apply quality control transformations\n",
    "trans = C.load_transformation(station, sensor)\n",
    "cleaned_data = C.transform(raw, trans)\n",
    "ts = cleaned_data[sensor]\n",
    "\n",
    "print(f\"Data cleaning complete!\")\n",
    "print(f\"Original data points: {len(raw)}\")\n",
    "print(f\"Cleaned data points: {len(ts)}\")\n",
    "print(f\"Data availability: {data_availability(ts):.1%}\")\n",
    "print(f\"Time range raw: {raw.index.min()} to {raw.index.max()}\")\n",
    "print(f\"Time range clean: {ts.index.min()} to {ts.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utide_analysis",
   "metadata": {},
   "source": [
    "## 1: UTide Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de8026",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = utide_get_coefs(ts, _lat, resample=20)\n",
    "print(f\"Found {len(out['name'])} tidal constituents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utide_results",
   "metadata": {},
   "source": [
    "Let's organize the UTide results into a clean DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 20 tidal constituents by amplitude (UTide):\")\n",
    "print(utide_to_df(out).sort_values('amplitude', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pytides_analysis",
   "metadata": {},
   "source": [
    "## 2: PyTides Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pytides = pytide_get_coefs(ts, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0dc4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pytides = pytide_get_coefs(ts, 20)\n",
    "print(f\"Found {len(out_pytides.model['constituent'])} tidal constituents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pytides_results",
   "metadata": {},
   "source": [
    "Let's organize the PyTides results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d4963",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 20 tidal constituents by amplitude (PyTides):\")\n",
    "print(pytides_to_df(out_pytides).sort_values('amplitude', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02049896",
   "metadata": {},
   "source": [
    "## 3: FES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af570562",
   "metadata": {},
   "outputs": [],
   "source": [
    "fes_cfg = get_pyfes_cfg(\"fes2022.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fes_df = get_constituents_fes(fes_cfg, station_info['lon'].values[0], station_info['lat'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_prep",
   "metadata": {},
   "source": [
    "## 4. Comparison\n",
    "To fairly compare UTide and pytides results, we'll standardize them against the FES 2022 constituent list. This will show us:\n",
    "\n",
    "1. Which constituents each method found\n",
    "2. Which constituents are missing from each analysis\n",
    "3. How the amplitudes compare for common constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytides_reduced_coef = reduce_coef_to_fes(pytides_to_df(out_pytides), FES_CONSTITUENTS)\n",
    "pytides_reduced_coef.head(10)\n",
    "\n",
    "utide_reduced_coef = reduce_coef_to_fes(utide_to_df(out), FES_CONSTITUENTS)\n",
    "utide_reduced_coef.head(10)\n",
    "\n",
    "fes_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visual_comparison",
   "metadata": {},
   "source": [
    "### visual comparison\n",
    "\n",
    "**What to look for:**\n",
    "- **Major constituents** (M2, S2, N2, K1, O1) should have similar amplitudes\n",
    "- **Minor constituents** may show more variation between methods\n",
    "- **Missing constituents** appear as zero amplitude in one method but not the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef00c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tide_ = concat_tides_constituents({\n",
    "    \"fes\":fes_df, \n",
    "    \"utide\":utide_reduced_coef, \n",
    "    \"pytides\": pytides_reduced_coef\n",
    "})\n",
    "tide_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparative_amplitudes(df, station):\n",
    "    return df.amplitude.hvplot.barh(\n",
    "        ylabel=\"Tidal Constituent\",\n",
    "        xlabel=\"Amplitude (meters)\", \n",
    "        by=\"method\", \n",
    "        grid=True,\n",
    "        title=f\"Tidal Amplitudes: UTide vs PyTide, station {station}\",\n",
    "        legend='top_right',\n",
    "        rot=90\n",
    "    ).opts(\n",
    "        height=1000, \n",
    "        width=1000,\n",
    "        fontsize={'title': 15, 'labels': 12, 'xticks': 8, 'yticks': 8}\n",
    "    )\n",
    "\n",
    "plot_comparative_amplitudes(tide_, station)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944890cb",
   "metadata": {},
   "source": [
    "### Quantitave comparison\n",
    "\n",
    "we'll assess the RSS between the all the consituents, taking pytide as the reference: \n",
    "\n",
    "RSS is given by: [1]\n",
    "\n",
    "$$\n",
    "\\operatorname{RSS} = \\sum_{i=1}^{n} \\left(A_{pytides,i} - A_{utide,i}\\right)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180dac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rss(df:pd.DataFrame, param:str, a:str, b:str):\n",
    "    df_ = df[param].unstack(level='method')\n",
    "    df_[\"rss\"] = (df_[a] - df_[b])**2\n",
    "    return df_[\"rss\"].sum()\n",
    "\n",
    "\n",
    "print(f\"utide rss for {station} is {compute_rss(tide_, 'amplitude', 'utide', 'fes'):.3f}\")\n",
    "print(f\"pytides rss for {station} is {compute_rss(tide_, 'amplitude', 'pytides', 'fes'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d0036",
   "metadata": {},
   "source": [
    "we'll iterate though an existing folder, contaning clean data at tide gauge locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac40cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for path in glob.glob(\"data/*parquet\"): \n",
    "    ts = pd.read_parquet(path)\n",
    "    ts = ts[ts.columns[0]]\n",
    "    root, file_ext = os.path.split(path)\n",
    "    file, ext = os.path.splitext(file_ext)\n",
    "    station, sensor = file.split(\"_\")\n",
    "    _lon = ioc_df[ioc_df.ioc_code == station].lon.values[0]\n",
    "    _lat = ioc_df[ioc_df.ioc_code == station].lat.values[0]\n",
    "    try: \n",
    "        # constituents\n",
    "        ut = utide_get_coefs(ts, _lat, resample=20)\n",
    "        utide_reduced_coef = reduce_coef_to_fes(utide_to_df(ut), FES_CONSTITUENTS)\n",
    "        pt = pytide_get_coefs(ts, 20.)\n",
    "        pytides_reduced_coef = reduce_coef_to_fes(pytides_to_df(pt), FES_CONSTITUENTS)\n",
    "        fes_df = get_constituents_fes(fes_cfg, _lon, _lat)\n",
    "        tide_ = concat_tides_constituents({\n",
    "            \"fes\":fes_df, \n",
    "            \"utide\":utide_reduced_coef, \n",
    "            \"pytides\": pytides_reduced_coef\n",
    "        })\n",
    "        rss_utide = compute_rss(tide_, \"amplitude\", \"utide\", \"fes\")\n",
    "        rss_pytides = compute_rss(tide_, \"amplitude\", \"pytides\", \"fes\")\n",
    "        # time domain\n",
    "        ts_fes = fes_reconstruct(lon=_lon, lat=_lat, dates=DATES, cfg=fes_cfg)\n",
    "        ts_fes_obs, _ = sim_on_obs(ts_fes, ts.loc[START:END])\n",
    "        df_sim_obs_fes = pd.concat({\n",
    "            \"fes\": ts_fes_obs/100, \n",
    "            \"obs\": ts.loc[START: END], \n",
    "            }, axis=1)\n",
    "        corr_matrix = df_sim_obs_fes.corr(method=\"pearson\")\n",
    "        corr_fes = corr_matrix.loc[\"fes\", \"obs\"]\n",
    "        score_utide = compute_score(corr_fes, float(rss_utide))\n",
    "        score_pytides = compute_score(corr_fes, float(rss_pytides))\n",
    "        # results for station\n",
    "        res[station] = {\n",
    "            \"ioc_code\": station,\n",
    "            \"lat\": _lat,\n",
    "            \"lon\": _lon,\n",
    "            \"rss_utide\": rss_utide,\n",
    "            \"rss_pytides\": rss_pytides,\n",
    "            \"corr_fes\": corr_fes,\n",
    "            \"score_utide\": score_utide,\n",
    "            \"score_pytides\": score_pytides\n",
    "        }\n",
    "        # print(f\"rss for {station} is {rss:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"couldn't process {station}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbb504",
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_df = pd.DataFrame(res).T\n",
    "rss_df.score_utide = rss_df.score_utide.astype(float)\n",
    "rss_df.score_pytides = rss_df.score_pytides.astype(float)\n",
    "rss_df.rss_utide = rss_df.rss_utide.astype(float)\n",
    "rss_df.rss_pytides = rss_df.rss_pytides.astype(float)\n",
    "rss_df[\"corr_fes\"] = rss_df[\"corr_fes\"].astype(float)\n",
    "rss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55ae10",
   "metadata": {},
   "source": [
    "### Visualing the RSS between Utide/pytides and FES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_df.hvplot.points(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\",\n",
    "    c=\"rss_utide\",\n",
    "    hover_cols = ['ioc_code'],\n",
    "    s=100,\n",
    "    geo = True,\n",
    "    tiles = True,\n",
    "    clim=(0,0.2)\n",
    ").opts(width = 1000, height = 800, title = \"RSS difference between UTide and FES constituents\")\n",
    "\n",
    "rss_df.hvplot.points(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\",\n",
    "    c=\"rss_pytides\",\n",
    "    hover_cols = ['ioc_code'],\n",
    "    s=100,\n",
    "    geo = True,\n",
    "    tiles = True,\n",
    "    clim=(0,0.2)\n",
    ").opts(width = 1000, height = 800, title = \"RSS difference between pytides and FES constituents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f4ad2",
   "metadata": {},
   "source": [
    "RSS between FES and observed constituents look very close globally. \n",
    "\n",
    "Let's look at the 2 worst stations: `anch2`, `live`\n",
    "\n",
    "The rest of the stations are quite quite with less than 0.2 m² RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "station= \"anch2\"\n",
    "\n",
    "tide_, ts_fes_obs = get_tidal_ts(station, ioc_df, fes_cfg)\n",
    "plot_comparative_amplitudes(tide_, station) + ts_fes_obs.resample(\"20min\").mean().shift(freq=\"10min\").hvplot().opts(height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c656b",
   "metadata": {},
   "source": [
    "anchorage in Alaska is deep in a fjord\n",
    "\n",
    "The tidal wave does not seem to be attenuated enough in the FES2022 model, \n",
    "\n",
    "here is a representation of the M2 constituent in Alaska:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = xr.open_dataset(\"/home/tomsail/work/FES/load_tide/m2_fes2022.nc\")\n",
    "M2_subset = M2.sel(lon=slice(205, 215),lat=slice(58,62))\n",
    "(M2_subset.amplitude.hvplot.image(\n",
    "    geo=True,\n",
    "    alpha=0.9,\n",
    "    tiles=True,\n",
    "    cmap='rainbow4',\n",
    "    clim = (0,3)\n",
    ")*M2_subset.phase.hvplot.contour(\n",
    "    geo=True,\n",
    ")*ioc_df[ioc_df.ioc_code == station].hvplot.points(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\", \n",
    "    geo=True,\n",
    "    color = \"r\",\n",
    "    line_color='k',\n",
    "    s=100,\n",
    "    hover_cols=\"ioc_code\"\n",
    ")).opts(width=1200, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "station= \"live\"\n",
    "\n",
    "tide_, ts_fes_obs = get_tidal_ts(station, ioc_df, fes_cfg)\n",
    "plot_comparative_amplitudes(tide_, station) + ts_fes_obs.resample(\"20min\").mean().shift(freq=\"10min\").hvplot().opts(height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aebf84",
   "metadata": {},
   "source": [
    "Here on the contrary the tidal wave seems too antenuated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d35681",
   "metadata": {},
   "outputs": [],
   "source": [
    "M2_subset = M2.sel(lon=slice(350, 360),lat=slice(52,56))\n",
    "(M2_subset.amplitude.hvplot.image(\n",
    "    geo=True,\n",
    "    alpha=0.7,\n",
    "    tiles=True,\n",
    "    cmap='rainbow4',\n",
    "    clim = (0,3)\n",
    ")*M2_subset.phase.hvplot.contour(\n",
    "    geo=True,\n",
    ")*ioc_df[ioc_df.ioc_code == station].hvplot.points(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\", \n",
    "    geo=True,\n",
    "    color = \"r\",\n",
    "    line_color='k',\n",
    "    s=100,\n",
    "    hover_cols=\"ioc_code\"\n",
    ")).opts(width=1200, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c40f24",
   "metadata": {},
   "source": [
    "### Visualisation of the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_df.hvplot.points(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\",\n",
    "    c=\"corr_fes\",\n",
    "    hover_cols = ['ioc_code'],\n",
    "    s=100,\n",
    "    cmap=\"rainbow4_r\",\n",
    "    geo = True,\n",
    "    tiles = True,\n",
    ").opts(width = 1000, height = 800, title = \"correlation between obs and FES reconstructed signal\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90863620",
   "metadata": {},
   "source": [
    "globally correlation between FES and **tidal-only** signal from tide gauges is very good. \n",
    "\n",
    "We can have a look at what is going on in the Baltic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a4451",
   "metadata": {},
   "outputs": [],
   "source": [
    "station= \"furu\"\n",
    "\n",
    "tide_, ts_fes_obs = get_tidal_ts(station, ioc_df, fes_cfg)\n",
    "plot_comparative_amplitudes(tide_, station) + ts_fes_obs.resample(\"20min\").mean().shift(freq=\"10min\").hvplot().opts(height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc0c82c",
   "metadata": {},
   "source": [
    "The biggest difference is in the `SSA`/`SA` constituents that have 12 and 6 months period. \n",
    "\n",
    "Preleminary conclusion is that FES is not able to account for these long period constituents in its T-UGO model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surge_analysis",
   "metadata": {},
   "source": [
    "### comparison between tidal residuals\n",
    "\n",
    "If both methods are working correctly, the tidal residuals - corresponding to the meteorological component - time series should be very similar. \n",
    "\n",
    "Significant differences would indicate problems with `utide`, `pytides` or both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac67de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to take a \"total water level\" observed signal\n",
    "file = glob.glob(f\"twl/{station}*.parquet\")\n",
    "ts = pd.read_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating storm surge using both methods...\")\n",
    "rsp = 30\n",
    "surge_pytides = pytides_surge(ts[ts.columns[0]], resample=rsp)\n",
    "surge_utide = utide_surge(ts[ts.columns[0]], _lat, resample=rsp)\n",
    "\n",
    "correlation = surge_pytides.corr(surge_utide)\n",
    "rmse = ((surge_pytides - surge_utide)**2).mean()**0.5\n",
    "\n",
    "print(f\"--------\\n📊 Storm Surge Comparison Results:\")\n",
    "print(f\"Correlation coefficient: {correlation:.4f}\")\n",
    "print(f\"RMSE between methods: {rmse:.3f} meters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(surge_pytides.resample(\"1h\").mean().hvplot(label=\"surge pytides\", grid=True)\n",
    " *surge_utide.resample(\"1h\").mean().hvplot(label=\"surge utide\")\n",
    " ).opts(\n",
    "    width=1200,\n",
    "    height = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b4a21",
   "metadata": {},
   "source": [
    "## Second part: chunked detiding (to be continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surge_chunked(ts: pd.Series, lat: float, resample: int = None, max_days: int = 365) -> pd.Series:\n",
    "    ts0 = ts.copy()\n",
    "    if resample is not None:\n",
    "        ts = ts.resample(f\"{resample}min\").mean()\n",
    "        ts = ts.shift(freq=f\"{resample / 2}min\")\n",
    "\n",
    "    OPTS = {\n",
    "        \"constit\": \"auto\",\n",
    "        \"method\": \"ols\",\n",
    "        \"order_constit\": \"frequency\",\n",
    "        \"Rayleigh_min\": 0.97,\n",
    "        \"lat\": lat,\n",
    "        \"verbose\": True\n",
    "    }\n",
    "\n",
    "    detided = pd.Series(index=ts0.index, dtype='float64')\n",
    "\n",
    "    t_start = ts.index.min()\n",
    "    t_end = ts.index.max()\n",
    "    chunk_start = t_start\n",
    "    chunk_size = pd.Timedelta(days = max_days)\n",
    "\n",
    "    while chunk_start < t_end:\n",
    "        current_chunk_size = chunk_size\n",
    "\n",
    "        while True:\n",
    "            chunk_end = chunk_start + current_chunk_size\n",
    "            if chunk_end > t_end:\n",
    "                chunk_end = t_end\n",
    "\n",
    "            chunk = ts[chunk_start:chunk_end]\n",
    "            avail = data_availability(chunk, freq=\"60min\")\n",
    "            total_days = current_chunk_size.total_seconds()/(3600*24)\n",
    "            if total_days*avail >= 365*0.9:\n",
    "                print(f\"Detiding chunk {chunk_start.date()} to {chunk_end.date()} ({avail*100:.1f}% available)\")\n",
    "                try:\n",
    "                    coef = utide.solve(\n",
    "                        chunk.index,\n",
    "                        chunk,\n",
    "                        **OPTS\n",
    "                    )\n",
    "                    recon_index = ts0.loc[chunk_start:chunk_end].index\n",
    "                    tidal = utide.reconstruct(recon_index, coef, verbose=OPTS[\"verbose\"])\n",
    "                    detided.loc[chunk_start:chunk_end] = ts0.loc[chunk_start:chunk_end].values - tidal.h\n",
    "                except Exception as e:\n",
    "                    print(f\"UTide failed on chunk {chunk_start} to {chunk_end}: {e}\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Data availability {avail:.1f}% from {chunk_start.date()} to {chunk_end.date()} — expanding chunk.\")\n",
    "                current_chunk_size += pd.Timedelta(days=6*30)\n",
    "                if chunk_start + current_chunk_size > t_end:\n",
    "                    print(\"End of time series reached with insufficient data.\")\n",
    "                    break\n",
    "\n",
    "        chunk_start = chunk_end\n",
    "\n",
    "    return detided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked = surge_chunked(ts, _lat, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(surge_pytides.resample(\"1h\").mean().hvplot(\n",
    "    label=\"sugre pytides\", grid=True\n",
    " )*surge_utide.resample(\"1h\").mean().hvplot(\n",
    "    label=\"surge utide\"\n",
    " )*chunked.resample(\"1h\").mean().hvplot(\n",
    "    label=\"chunked utide\"\n",
    " )).opts(\n",
    "    width=1200,\n",
    "    height = 500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
