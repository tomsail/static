{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.optimize import minimize_scalar\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "\n",
    "import function_GLOBCOASTS as FUNC\n",
    "\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEADATA_PATH = \"SEADATA_14140pts_1993_2019-analysed.nc\"\n",
    "BQART_PATH = \"Sorties_Bqart.txt\"\n",
    "TIDE_PATH = \"Tide_Glob.mat\"\n",
    "DEPTH_OF_CLOSURE = \"Dc.nc\"\n",
    "VALIDATION_DATA = 'Shorelines_global_20231101_shift.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616fae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLID RIVER DISCHARGE CALCULATED THROUGH BQART FORMULA WITH Te = 0.2 [Mt/yr]\n",
    "bqart_brut   = pd.read_csv(BQART_PATH, delimiter=';', header=None, names = [\"inflow\", \"outflow\"])\n",
    "bqart_brut\n",
    "bqart_m3     = bqart_brut[\"inflow\"]/2.650 #to convert it to m3\n",
    "bqart        = bqart_m3/12            # m3/yr --> m3/month\n",
    "bqart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e4a2d",
   "metadata": {},
   "source": [
    "load SEADATA NetCDF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6591475",
   "metadata": {},
   "outputs": [],
   "source": [
    "seadata = xr.open_dataset(SEADATA_PATH,engine='netcdf4')\n",
    "seadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a3c6e",
   "metadata": {},
   "source": [
    "fix time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vec = pd.date_range(\"1993\", \"2019-12-31\")\n",
    "assert(len(time_vec) == len(seadata.t))\n",
    "# so seadata_continents.t are days from 1993 until 2020\n",
    "seadata = seadata.assign_coords(t = time_vec)\n",
    "seadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80318941",
   "metadata": {},
   "source": [
    "fix land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1df81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seadata = seadata.assign_coords({\"lon\": seadata.lon, \"lat\": seadata.lat})\n",
    "seadata.Hs.isel(t=-1).hvplot.scatter(x=\"lon\", y=\"lat\", c=\"Hs\") + seadata.Hs.isel(t=-1).isel(pos=slice(0,8841)).hvplot.scatter(x=\"lon\", y=\"lat\", c=\"Hs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seadata_continents = seadata.isel(pos=slice(0, 8841))\n",
    "bqart_continents = bqart[:8841].values\n",
    "bqart_continents\n",
    "seadata_continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02755c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# TIDE INPUT TO COMPUTE SLOPE THROUGH SUNAMURA 84 MODIFIED FORMULA (Arias et al., 2025)\n",
    "TIDE        = scipy.io.loadmat(TIDE_PATH)\n",
    "Tide_range  = TIDE['Tide_max'][0][:8841] #m\n",
    "Tide_range.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# DYNAMICAL DEPTH OF CLOSURE (Young, 1995)\n",
    "Dc        = xr.open_dataset(DEPTH_OF_CLOSURE,engine='netcdf4')\n",
    "DoC       = Dc['Dc'].values #m\n",
    "DoC.shape\n",
    "# returns (240, 8841)\n",
    "# here the Depth of closure does not match the time vector in SEADATA\n",
    "# So it must be a monthly value but we need to know from when to when\n",
    "\n",
    "# however all the other dataset are 324 length so DOC must be enlarged artifically\n",
    "\n",
    "pad_length = 324 - DoC.shape[0]\n",
    "DoC_padded = np.vstack([DoC, np.tile(DoC[-1:], (pad_length, 1))])\n",
    "DoC_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c667d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# WORLDWIDE CALIBRATION COEFFICIENT\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# VALDIATION FILE : WATERLINE POSITION OBTAIN THANKS TO LANDSAT 7 AND 8 PRODUCTS\n",
    "Validation  = scipy.io.loadmat(VALIDATION_DATA)\n",
    "Xshores_val = Validation['X_safe'][:,108:-12]\n",
    "latX        = Validation['latX'][:]\n",
    "lonX        = Validation['lonX'][:]\n",
    "Xshores_VALIDATION = np.transpose((-1*Xshores_val))\n",
    "Xshores_VALIDATION.shape, latX.shape, lonX.shape\n",
    "# here the Validation matches the time vector in SEADATA > all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANT VALUES DECLARATION\n",
    "D50 = 10e-3         # Median grain size [m]\n",
    "PORO = 0.4          # Sand porosity\n",
    "ROHS = 2650         # Sand density [kg/m3]\n",
    "ROH = 1000          # Water density [kg/m3]\n",
    "G = 9.81            # gravitationnal acceleration [m/s2]\n",
    "R = 6371000         # Earth radius [m]\n",
    "NMONTHS = len(seadata.mounth)   # Number of time step\n",
    "NMONTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38900aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT CALCULATION \n",
    "# ---------------------------------------------------------------------------------------\n",
    "# TIDE CHECK FOR NAN VALUES\n",
    "for i in range(1,len(Tide_range)):\n",
    "        if str(Tide_range[i]) == 'nan':\n",
    "            Tide_range[i]=Tide_range[i-1]\n",
    "            \n",
    "print(\"# - Tide range is cleaned\")\n",
    "np.isnan(Tide_range).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# SOLID RIVER DISCHARGE VARIABILITY THROUGH THE USE OF ISBA-CTRIP DATASET \n",
    "# 1. CLEAN LIQUID RIVER DISCHARGE DATASET (ISBA-CTRIP)\n",
    "seadata_continents['rivdis_mounthly'] = seadata_continents['rivdis_mounthly'].fillna(0)\n",
    "# 2. SOLID RIVER DISCHARGE VARIBILITY CALCUL\n",
    "QrivD = FUNC.RIVDIS(seadata_continents['rivdis_mounthly'].T,bqart_continents[0])\n",
    "np.isnan(QrivD).sum()\n",
    "QrivD.shape\n",
    "print(\"# - QrivD is ok\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86113ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------\n",
    "# TOTAL WATER LEVEL CALCUL\n",
    "# 1. Foreshore Beach slope calculation through SUNAMURA 84 modified by tide (Arias et al., 2025)\n",
    "\n",
    "def wl(Tp):\n",
    "    return (G/(2*np.pi))*Tp**2\n",
    "def beta_fun(Tp, Hs):\n",
    "    return 0.12 * ((np.sqrt(2*np.pi*D50*wl(Tp)))/(Hs+Tide_range))**0.5 #slope\n",
    "\n",
    "beta = beta_fun(seadata_continents[\"Tp_mounthly\"], seadata_continents[\"Hs_mounthly\"])\n",
    "beta.isnull().sum()\n",
    "print(\"# - Foreshore slopes is ok \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Wave set up (Stockdon,2006 ) -> Approximation of a linear slope\n",
    "def setup(Hs, Tp):\n",
    "    return 0.35*beta*np.sqrt(Hs*wl(Tp)) #[m]\n",
    "\n",
    "setup_ = setup(seadata_continents[\"Tp_mounthly\"], seadata_continents[\"Hs_mounthly\"])\n",
    "setup_.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac406927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Sum of sea level anomaly (SLA), storm surge (DAC) and wave set-up (SU)\n",
    "twl  = seadata_continents[\"sla_mounthly\"] + seadata_continents[\"dac_mounthly\"] + setup_\n",
    "twl.isnull().sum()\n",
    "print(\"# - Total water level is ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef19a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAT/LON PRE-TREATMENT TO GET RIDE OF SATELLITE \"JUMPS\"\n",
    "# ---------------------------------------------------------------------------------------\n",
    "#1. Search for the index of position spaced by less than 0.55° to determine the zones (0.55 is the max resolution of our dataset)\n",
    "lon, lat = seadata_continents.lon.values, seadata_continents.lat.values\n",
    "start_index, end_index = FUNC.find_index(lon, lat,0.55)\n",
    "\n",
    "#2. Zone creation through the fusion of lat/lon \n",
    "join_section,join_index = FUNC.join_sections(start_index, end_index, lon, lat,0.55)\n",
    "\n",
    "#3. Selection of the zone that have more than 2 position\n",
    "join_section_filtered = [(i, j) for i, j in join_index if np.abs(i - j) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00905f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.arctan2(np.diff(lat),np.diff(lon))\n",
    "alpha = np.append(alpha, alpha[-1])\n",
    "normal = alpha+np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate incident angle\n",
    "def get_incident_angle(wave_dir, normal): \n",
    "    return np.mod(wave_dir - normal, 2*np.pi)\n",
    "\n",
    "incident_angle = get_incident_angle(np.radians(seadata_continents[\"dir_mounthly\"]), normal)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"lon\":lon,\n",
    "    \"lat\":lat,\n",
    "    \"normal\":normal,\n",
    "    \"wave_angle\":np.radians(seadata_continents[\"dir_mounthly\"][0, :]),\n",
    "    \"incident_angle\":incident_angle[1],\n",
    "    \"magnitude\":np.ones(len(lon)),\n",
    "    \n",
    "})\n",
    "df['index'] = df.index\n",
    "hv.Scatter(df, kdims=['lon', 'lat']).opts(width=1000, height=500, tools = ['hover'],size=20,color=\"index\", colorbar=True, colorbar_opts={\"title\":\"node number\"})*\\\n",
    "hv.VectorField(df, kdims=['lon', 'lat'], vdims=['normal','magnitude']).opts(width=1000, height=500,  scale = 0.01)\n",
    "\n",
    "hv.Scatter(df, kdims=['lon', 'lat']).opts(width=1000, height=500, tools = ['hover'],size=20,color=\"incident_angle\", colorbar=True, cmap=\"colorwheel\", colorbar_opts={\"title\":\"incident angle\"})*\\\n",
    "hv.VectorField(df, kdims=['lon', 'lat'], vdims=['normal','magnitude']).opts(width=1000, height=500,  scale = 0.01)*\\\n",
    "hv.VectorField(df, kdims=['lon', 'lat'], vdims=['wave_angle','magnitude']).opts(width=1000, height=500,  scale = 0.01, line_dash=\"dashed\", title = \"incident angle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c6d2e",
   "metadata": {},
   "source": [
    "we can see the global trends of offshore waves on the east coast and onshore wave on the west coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def twl(seadata_continents, t, idx, incidence_angle, setup_):\n",
    "    twl = seadata_continents[\"sla_mounthly\"][t,idx] + seadata_continents[\"dac_mounthly\"][t,idx] + (np.cos(incidence_angle[t,idx])*setup_[t,idx]) \n",
    "    return twl\n",
    "\n",
    "def kamp_mass(Tp, Hs, incident_angle, roh = ROH, rohs = ROHS, d50 = D50):\n",
    "    kamp_mass_i = 2.33 * (rohs / (rohs - roh)) * (Tp ** 1.5) * (np.tan(beta) ** 0.75) * (d50 ** -0.25) * (Hs ** 2) * np.abs(np.sin(2 * incident_angle)) ** 0.6 * np.sign(incident_angle)\n",
    "    return kamp_mass_i\n",
    "\n",
    "def kamp_in_m3_per_month(kamp_mass, roh = ROH, rohs = ROHS, poro = PORO):\n",
    "    return 86400 * 30 * (kamp_mass / (rohs - roh)) / (1.0 - poro)\n",
    "\n",
    "def compute_morpho_tot(DoC, QrivD, Ls, beta, t, idx, j, dkamp, dt):\n",
    "    a = -1 / DoC[t,idx]\n",
    "    b = (dkamp[t, idx] + QrivD[t, idx]) / Ls[j]\n",
    "    c = 1 / (np.tan(beta[t, idx]))\n",
    "    d = 1 / (np.tan(beta[t - 1, idx]))\n",
    "    return (a * b + (c - d)) * dt\n",
    "\n",
    "def compute_morpho_lst(DoC, QrivD, Ls, t, idx, j, dkamp, dt):\n",
    "    return ((-1 / DoC[t,idx]) * ((dkamp[t, idx] + QrivD[t, idx]) / Ls[j])) * dt\n",
    "\n",
    "def compute_morpho_xshore(beta, t, idx, dt):\n",
    "    return ((1 / (np.tan(beta[t,idx]))) - (1 / (np.tan(beta[t - 1, idx])))) * dt\n",
    "\n",
    "# MAIN LOOP\n",
    "# ---------------------------------------------------------------------------------------\n",
    "dt = 1                            # time step 1 month\n",
    "\n",
    "\n",
    "kamp_mass_i = kamp_mass(seadata_continents[\"Tp_mounthly\"],seadata_continents[\"Hs_mounthly\"], incident_angle)\n",
    "kamp_mass_ip1 = kamp_mass(np.roll(seadata_continents[\"Tp_mounthly\"],1,axis=1),np.roll(seadata_continents[\"Hs_mounthly\"],1,axis=1), incident_angle)\n",
    "kamp_i = kamp_in_m3_per_month(kamp_mass_i)\n",
    "kamp_ip1 = kamp_in_m3_per_month(kamp_mass_ip1)\n",
    "dkamp = kamp_ip1 - kamp_i\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"lon\":lon,\n",
    "    \"lat\":lat,\n",
    "    \"normal\":normal,\n",
    "    \"kamp\":kamp_i.isel(mounth=-1).data,\n",
    "    \"kamp_p1\":kamp_ip1.isel(mounth=-1).data,\n",
    "    \"dkamp\":dkamp.isel(mounth=-1).data\n",
    "    \n",
    "})\n",
    "\n",
    "df2.hvplot.scatter(x=\"lon\", y=\"lat\", c=\"dkamp\").opts(clim=(-1e5, 1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. FIRST SPATIAL LOOP WHICH SELECT EACH JOIN SECTION INDEPENDENTLY\n",
    "for i, section in tqdm(enumerate(join_section_filtered)):\n",
    "    start_index                 = section[0]\n",
    "    end_index                   = section[1]\n",
    "\n",
    "    index                       = np.arange(start_index, end_index)\n",
    "    zone_length                 = len(index)\n",
    "\n",
    "    # a. INITIALISATION OF RESULTS TABLE FOR THE SECTION\n",
    "    dKAMP                       = np.zeros((NMONTHS, zone_length))\n",
    "    dTWL                        = np.zeros((NMONTHS, zone_length))\n",
    "    twl_                         = np.zeros((NMONTHS, zone_length))\n",
    "\n",
    "    dx_CS_Hydro                 = np.zeros((NMONTHS, zone_length))\n",
    "    dx_CS_MorphoLST             = np.zeros((NMONTHS, zone_length))\n",
    "    dx_CS_MorphoTOT             = np.zeros((NMONTHS, zone_length))\n",
    "    dx_CS_MorphoXshore          = np.zeros((NMONTHS, zone_length))\n",
    "    dx_CS_TOTAL                 = np.zeros((NMONTHS, zone_length))\n",
    "\n",
    "    Lon                         = np.zeros((NMONTHS, zone_length))\n",
    "    Lat                         = np.zeros((NMONTHS, zone_length))\n",
    "    DLon                        = np.zeros((NMONTHS, zone_length))\n",
    "    DLat                        = np.zeros((NMONTHS, zone_length))\n",
    "\n",
    "    X_CS_MorphoLST              = np.zeros((NMONTHS, zone_length))\n",
    "    X_CS_MorphoTOT              = np.zeros((NMONTHS, zone_length))\n",
    "    X_CS_Hydro                  = np.zeros((NMONTHS, zone_length))\n",
    "    X_CS_MorphoXshore           = np.zeros((NMONTHS, zone_length))\n",
    "    X_CS_TOTAL                  = np.zeros((NMONTHS, zone_length))\n",
    "\n",
    "    # b. PRE-PROCESS OF LAT/LON DATA - AS WE CONVERT THEM IN METERS WE TAKE THE MID VALUES AS A REFERENCE\n",
    "    lat_mid = np.mean(lat[index])\n",
    "    lon_mid = np.mean(lon[index])\n",
    "    Lon_m, Lat_m = FUNC.lonlat2xy(lon[index], lat[index], lon_mid, lat_mid)\n",
    "\n",
    "    # DISTANCE TWO CONSECUTIVE POINT CALCULTION IN METERS\n",
    "    dLon = np.diff(Lon_m)\n",
    "    dLat = np.diff(Lat_m)\n",
    "    dLon = np.append(dLon, 0)\n",
    "    dLat = np.append(dLat, 0)\n",
    "    Ls = np.sqrt(dLon ** 2 + dLat ** 2)\n",
    "    smooth_Ls = 1.5 * Ls  # m\n",
    "\n",
    "    # d. TIME LOOP\n",
    "    print(NMONTHS-1)\n",
    "    for t in range(1, NMONTHS-1):\n",
    "        #d.1. FOR EACH COASTPOINT WE COMPUTE THE DELTA COASTLINE VARIABILITY\n",
    "        for j in range(zone_length - 1):\n",
    "            idx                  = index[j]                            #we associate the section point index to the global dataset \n",
    "            # print(idx)\n",
    "            # TOTAL WATER LEVEL COMPUTATION TAKING INTO ACCOUNT THE LOCAL INCIDENCE ANGLE\n",
    "            # TWL[t,j]             = seadata_continents[\"sla_mounthly\"][t,idx] + seadata_continents[\"dac_mounthly\"][t,idx] + (np.cos(incidence_angle[t,idx])*setup_[t,idx]) \n",
    "            twl_[t,j] = twl(seadata_continents, t, idx, incident_angle, setup_)\n",
    "            dTWL[t, j]           = twl_[t,j] - twl_[t-1,j]\n",
    "            dx_CS_Hydro[t, j]    = - (twl_[t,j] - twl_[t-1,j]) / (np.tan(beta[t, idx]))  # m\n",
    "\n",
    "            # MORPHOLOGICAL COMPONENT - LONGSHORE TRANSPORT RATE (KAMPHUIS, 1991)\n",
    "            incidence_angle_ip1  = incident_angle[t, idx + 1]\n",
    "            incidence_angle_i    = incident_angle[t, idx]  # radians\n",
    "\n",
    "            dx_CS_MorphoTOT[t, j] = compute_morpho_tot(DoC_padded,QrivD, Ls, beta, t, idx,j, dkamp, dt).values\n",
    "            dx_CS_MorphoLST[t, j] = compute_morpho_lst(DoC_padded, QrivD, Ls, t, idx, j, dkamp, dt)\n",
    "            dx_CS_MorphoXshore[t, j] = compute_morpho_xshore(beta, t, idx, dt)\n",
    "            # TOTAL DELTA\n",
    "            dx_CS_TOTAL[t,j]      = dx_CS_Hydro[t,j] + dx_CS_MorphoTOT[t,j]\n",
    "\n",
    "        # WHEN ALL DELTA POSITION COMPUTED WE ADD THEM FOR EACH TIME STEP TO THE PREVIOUS CROSS-SHORE POSITION (m)\n",
    "        # COMPONENT\n",
    "        X_CS_Hydro[t, :]          = X_CS_Hydro[t - 1, :] + dx_CS_Hydro[t, :]\n",
    "        X_CS_MorphoTOT[t, :]      = X_CS_MorphoTOT[t - 1, :] + dx_CS_MorphoTOT[t, :]\n",
    "        X_CS_MorphoLST[t, :]      = X_CS_MorphoLST[t - 1, :] + dx_CS_MorphoLST[t, :]\n",
    "        X_CS_MorphoXshore[t, :]   = X_CS_MorphoXshore[t - 1, :] + dx_CS_MorphoXshore[t, :]\n",
    "\n",
    "        # TOTAL\n",
    "        X_CS_TOTAL[t,:]           = X_CS_TOTAL[t-1,:] + dx_CS_TOTAL[t,:]\n",
    "        \n",
    "        # PROJECTION FROM CARTESIAN TO GEOGRAPHICAL (meters)\n",
    "        DLon[t,:]                 = - dx_CS_TOTAL[t,:]  * np.sin(normal[index])\n",
    "        DLat[t,:]                 =   dx_CS_TOTAL[t,:]  * np.cos(normal[index])\n",
    "\n",
    "        time0 = time.time()\n",
    "        DLon[t,:]                 = FUNC.Wfilter(DLon[t,:],Lon_m,Lat_m,smooth_Ls)\n",
    "        DLat[t,:]                 = FUNC.Wfilter(DLat[t,:],Lon_m,Lat_m,smooth_Ls)\n",
    "        # print(np.shape(DLon))\n",
    "        # print(np.shape(Lon_m))\n",
    "        # print(np.shape(smooth_Ls))\n",
    "        # UPDATING THE COORDINATES \n",
    "        Lon_m                     = Lon_m + DLon[t]\n",
    "        Lat_m                     = Lat_m + DLat[t]\n",
    "        \n",
    "        # CONVERTING IN °\n",
    "        Lon[t,:],Lat[t,:]         = FUNC.xy2lonlat(Lon_m, Lat_m, lon_mid, lat_mid)\n",
    "        # print(time.time()- time0)\n",
    "\n",
    "    break\n",
    "    # #e. FOR EACH SECTION WE STOCK THE RESULTS\n",
    "    # r_index.append(index)\n",
    "    # r_dKAMP.append(dKAMP)\n",
    "    # r_dTWL.append(dTWL)\n",
    "    # r_TWL.append(TWL)\n",
    "\n",
    "    # r_Ls.append(Ls)\n",
    "    # r_alpha.append(alpha)\n",
    "    # r_normal.append(normal)\n",
    "    # r_incidence_angle.append(incidence_angle)\n",
    "    \n",
    "    # r_dx_CS_Hydro.append(dx_CS_Hydro)\n",
    "    # r_dx_CS_MorphoLST.append(dx_CS_MorphoLST)\n",
    "    # r_dx_CS_MorphoTOT.append(dx_CS_MorphoTOT)\n",
    "    # r_dx_CS_MorphoXshore.append(dx_CS_MorphoXshore)\n",
    "    # r_dx_CS_TOTAL.append(dx_CS_TOTAL)\n",
    "    \n",
    "    # r_X_CS_MorphoLST.append(X_CS_MorphoLST)\n",
    "    # r_X_CS_MorphoTOT.append(X_CS_MorphoTOT)\n",
    "    # r_X_CS_Hydro.append(X_CS_Hydro)\n",
    "    # r_X_CS_MorphoXshore.append(X_CS_MorphoXshore)\n",
    "    # r_X_CS_TOTAL.append(X_CS_TOTAL)\n",
    "\n",
    "    # r_Lon.append(Lon)\n",
    "    # r_Lat.append(Lat)\n",
    "    # r_Lon_m.append(Lon_m)\n",
    "    # r_Lat_m.append(Lat_m)\n",
    "    # r_DLon.append(DLon)\n",
    "    # r_DLat.append(DLat)\n",
    "    # r_dLon.append(dLon)\n",
    "    # r_dLat.append(dLat)\n",
    "\n",
    "lon[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# 1. FIRST SPATIAL LOOP WHICH SELECT EACH JOIN SECTION INDEPENDENTLY\n",
    "for i, section in tqdm(enumerate(join_section_filtered)):\n",
    "    start_index                 = section[0]\n",
    "    end_index                   = section[1]\n",
    "    index                       = np.arange(start_index, end_index)\n",
    "    im = ax.scatter(lon[index], lat[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754fb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# CONCATENATION OF THE RESULTS\n",
    "# ---------------------------------------------------------------------------------------\n",
    "results_dKAMP              = np.concatenate(r_dKAMP, axis=1)\n",
    "results_dTWL               = np.concatenate(r_dTWL, axis=1)\n",
    "results_TWL                = np.concatenate(r_TWL, axis=1)\n",
    "\n",
    "results_Ls                 = np.concatenate(r_Ls, axis=1)\n",
    "results_alpha              = np.concatenate(r_alpha, axis=1)\n",
    "\n",
    "results_normal             = np.concatenate(r_normal, axis=1)\n",
    "results_incidence_angle    = np.concatenate(r_incidence_angle, axis=1)\n",
    "\n",
    "results_dx_CS_Hydro        = np.concatenate(r_dx_CS_Hydro, axis=1)\n",
    "results_dx_CS_MorphoLST    = np.concatenate(r_dx_CS_MorphoLST, axis=1)\n",
    "results_dx_CS_MorphoTOT    = np.concatenate(r_dx_CS_MorphoTOT, axis=1)\n",
    "results_dx_CS_MorphoXshore = np.concatenate(r_dx_CS_MorphoXshore, axis=1)\n",
    "results_dx_CS_TOTAL        = np.concatenate(r_dx_CS_TOTAL, axis=1)\n",
    "\n",
    "results_X_CS_MorphoLST     = np.concatenate(r_X_CS_MorphoLST, axis=1)\n",
    "results_X_CS_MorphoTOT     = np.concatenate(r_X_CS_MorphoTOT, axis=1)\n",
    "results_X_CS_Hydro         = np.concatenate(r_X_CS_Hydro, axis=1)\n",
    "results_X_CS_MorphoXshore  = np.concatenate(r_X_CS_MorphoXshore, axis=1)\n",
    "results_X_CS_TOTAL         = np.concatenate(r_X_CS_TOTAL, axis=1)\n",
    "  \n",
    "results_Lon                = np.concatenate(r_Lon, axis=1)\n",
    "results_Lat                = np.concatenate(r_Lat, axis=1)\n",
    "results_Lon_m              = np.concatenate(r_Lon_m, axis=1)\n",
    "results_Lat_m              = np.concatenate(r_Lat_m, axis=1)\n",
    "results_DLon               = np.concatenate(r_DLon, axis=1)\n",
    "results_DLat               = np.concatenate(r_DLat, axis=1)\n",
    "results_dLon               = np.concatenate(r_dLon, axis=1)\n",
    "results_dLat               = np.concatenate(r_dLat, axis=1)\n",
    "results_index              = np.concatenate(r_index)\n",
    "\n",
    "# Calibration of our seasonal cycles \n",
    "date_list= pd.date_range('2000-1-1','2019-12-31', freq='ME').strftime(\"%Y-%m-%d\")\n",
    "date = pd.DatetimeIndex(date_list)\n",
    "num_dates = len(date_list)\n",
    "lon_len = Xshores_val.shape[1]\n",
    "\n",
    "print(results_X_CS_MorphoTOT.shape)\n",
    "print(results_Lat.shape)\n",
    "print(results_Lon.shape)\n",
    "print(results_dx_CS_Hydro.shape)\n",
    "print(results_dx_CS_MorphoLST.shape)\n",
    "print(results_dx_CS_MorphoTOT.shape)\n",
    "print(results_dx_CS_MorphoXshore.shape)\n",
    "print(results_dx_CS_TOTAL.shape)\n",
    "\n",
    "ds = xr.Dataset(data_vars=\n",
    "    {\n",
    "        \"results_dx_CS_Hydro\": ((\"time\", \"node\"), results_dx_CS_Hydro),\n",
    "        \"results_dx_CS_MorphoLST\": ((\"time\", \"node\"), results_dx_CS_MorphoLST),\n",
    "        \"results_dx_CS_MorphoTOT\": ((\"time\", \"node\"), results_dx_CS_MorphoTOT),\n",
    "        \"results_dx_CS_MorphoXshore\": ((\"time\", \"node\"), results_dx_CS_MorphoXshore),\n",
    "        \"results_dx_CS_TOTAL\": ((\"time\", \"node\"), results_dx_CS_TOTAL),\n",
    "        \"x\": ((\"time\", \"node\"), results_Lon_m),\n",
    "        \"y\": ((\"time\", \"node\"), results_Lat_m)\n",
    "    }, \n",
    "    coords={\n",
    "        \"lon\": results_Lon[0,:], \n",
    "        \"lat\": results_Lat[0,:]\n",
    "    }, \n",
    ")\n",
    "\n",
    "print(ds)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.scatter(ds.lon, ds.lat, c = ds.results_dx_CS_TOTAL.mean(dim=\"time\"), vmax=1, vmin=-1)\n",
    "plt.colorbar(im)\n",
    "plt.title(\"results_dx_CS_TOTAL\")\n",
    "plt.show()\n",
    "# stop here, script does not work aferwards\n",
    "\n",
    "VALIDATION_POSITION = {f\"Position_{i}\": Xshores_val[:, i] for i in range(lon_len)}\n",
    "VALIDATION = pd.DataFrame(VALIDATION_POSITION)\n",
    "print(VALIDATION_POSITION)\n",
    "print(VALIDATION)\n",
    "print(X_CS_TOTAL.shape)\n",
    "MODELE_POSITION = {f\"Position_{i}\": X_CS_TOTAL[i,:] for i in range(lon_len)}\n",
    "MODELE = pd.DataFrame(MODELE_POSITION)\n",
    "\n",
    "print(MODELE)\n",
    "print(MODELE_POSITION)\n",
    "\n",
    "def compute_seasonal_cycle_np(X, dates):\n",
    "    \"\"\"\n",
    "    Calcule le cycle saisonnier moyen d'une série temporelle.\n",
    "\n",
    "    Paramètres:\n",
    "    - X (array): Série temporelle.\n",
    "    - dates (pd.DatetimeIndex): Index temporel contenant les dates.\n",
    "\n",
    "    Retourne:\n",
    "    - seasonal_cycle (array): Cycle saisonnier moyen (taille = 12 mois).\n",
    "    \"\"\"\n",
    "    months = dates.month  # Extraire les mois\n",
    "    seasonal_cycle = np.array([np.mean(X[months == m]) for m in range(1, 13)])  # Moyenne par mois\n",
    "    return seasonal_cycle\n",
    "\n",
    "#  Fonction pour ajuster MODELE avant le calcul du cycle saisonnier\n",
    "def transform_MODELE(c, X_MODELE):\n",
    "    \"\"\"\n",
    "    Applique une transformation linéaire à X_MODELE.\n",
    "\n",
    "    Paramètres:\n",
    "    - c (float): Coefficient multiplicatif.\n",
    "    - X_MODELE (array): Série temporelle originale.\n",
    "\n",
    "    Retourne:\n",
    "    - X_transformed (array): Série ajustée.\n",
    "    \"\"\"\n",
    "    return X_MODELE * c  # Multiplication par c pour ajustement\n",
    "\n",
    "#  Fonction pour calculer la RMSE après transformation et cycle saisonnier\n",
    "def compute_rmse_c(c, X_MODELE, X_VALIDATION, dates):\n",
    "    \"\"\"\n",
    "    Transforme X_MODELE, calcule son cycle saisonnier et compare avec X_VALIDATION.\n",
    "\n",
    "    Paramètres:\n",
    "    - c (float): Coefficient multiplicatif.\n",
    "    - X_MODELE (array): Série temporelle originale.\n",
    "    - X_VALIDATION (array): Cycle saisonnier de validation (taille 12).\n",
    "    - dates (pd.DatetimeIndex): Index temporel contenant les dates.\n",
    "\n",
    "    Retourne:\n",
    "    - RMSE (float): Erreur quadratique moyenne.\n",
    "    \"\"\"\n",
    "    X_transformed = transform_MODELE(c, X_MODELE)  # Appliquer la transformation\n",
    "    seasonal_cycle_MODELE = compute_seasonal_cycle_np(X_transformed, dates)  # Calcul du cycle saisonnier\n",
    "    seasonal_cycle_VALIDATION = compute_seasonal_cycle_np(X_VALIDATION, dates)  # Cycle saisonnier de validation\n",
    "    \n",
    "    return np.sqrt(np.mean((seasonal_cycle_MODELE - seasonal_cycle_VALIDATION) ** 2))  # Calcul de la RMSE\n",
    "# Liste des positions à analyser\n",
    "positions_to_plot = [f\"Position_{i}\" for i in range(Xshores_val.shape[1])]\n",
    "\n",
    "# Stocker les résultats optimaux\n",
    "optimal_c_values = {}\n",
    "\n",
    "#  Boucle sur chaque position pour optimiser c\n",
    "for pos in positions_to_plot:\n",
    "    X_MODELE = MODELE[pos].values  # Extraire la série MODELE (array)\n",
    "    X_VALIDATION = VALIDATION[pos].values  # Extraire la série VALIDATION (array)\n",
    "    dates = MODELE.index  # Récupérer les dates\n",
    "\n",
    "    # Recherche du meilleur c qui minimise la RMSE\n",
    "    result = minimize_scalar(\n",
    "        compute_rmse_c, \n",
    "        bounds=(-50, 50),  # Plage de recherche\n",
    "        args=(X_MODELE, X_VALIDATION, dates), \n",
    "        method=\"bounded\"\n",
    "    )\n",
    "\n",
    "    # Extraction du c optimal\n",
    "    c_optimal = result.x\n",
    "    rmse_min = result.fun\n",
    "    optimal_c_values[pos] = c_optimal  # Stocker le meilleur c\n",
    "\n",
    "    print(f\" {pos} - Meilleur c: {c_optimal:.6f}, RMSE minimale: {rmse_min:.10f}\")\n",
    "\n",
    "    #  Visualisation de l'évolution de la RMSE en fonction de c\n",
    "    c_values = np.linspace(c_optimal - 2, c_optimal + 2, 500)  # Générer plusieurs valeurs de c\n",
    "    rmse_values = [compute_rmse_c(c, X_MODELE, X_VALIDATION, dates) for c in c_values]  # Calcul de la RMSE\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(c_values, rmse_values, label=\"RMSE vs c\", linewidth=2)\n",
    "    plt.axvline(c_optimal, color='red', linestyle='--', label=f\"Optimal c = {c_optimal:.6f}\")\n",
    "    plt.xlabel(\"Coefficient c\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(f\"Évolution de la RMSE pour {pos}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    #  Comparaison des cycles saisonniers avant et après ajustement\n",
    "    X_transformed_optimal = transform_MODELE(c_optimal, X_MODELE)\n",
    "    seasonal_cycle_optimal = compute_seasonal_cycle_np(X_transformed_optimal, dates)\n",
    "    seasonal_cycle_original = compute_seasonal_cycle_np(X_MODELE, dates)\n",
    "    seasonal_cycle_validation = compute_seasonal_cycle_np(X_VALIDATION, dates)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(seasonal_cycle_validation, label=\"Cycle Validation (Xval)\", color=\"blue\", linewidth=2)\n",
    "    plt.plot(seasonal_cycle_original, label=\"Cycle MODELE Original\", color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.plot(seasonal_cycle_optimal, label=f\"Cycle Ajusté (c={c_optimal:.6f})\", color=\"red\", linewidth=2)\n",
    "\n",
    "    plt.xlabel(\"Mois\")\n",
    "    plt.ylabel(\"Valeur\")\n",
    "    plt.title(f\"Comparaison des Cycles Saisonniers pour {pos}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    #  Affichage final des meilleurs coefficients c\n",
    "print(\"\\n Meilleurs coefficients c trouvés pour chaque position :\")\n",
    "for pos, c_value in optimal_c_values.items():\n",
    "    print(f\"{pos}: c = {c_value:.6f}\")\n",
    "\n",
    "X_GLOBCOASTS_CALIBRE = c_value * X_CS_TOTAL\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# POST TREATMENT OF THE RESULTS\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# a. TEMPORAL SMOOTH OVER 3 MONTHS \n",
    "# Define the sigma (standard deviation) for Gaussian smoothing\n",
    "# Assuming an approximate 30-day window, adjust sigma based on your data frequency\n",
    "\n",
    "sigma = 1.0  # This will smooth over approximately 3 months, adjust as needed\n",
    "\n",
    "X_TOTAL_detrend             = FUNC.gaussian_smooth(results_X_CS_TOTAL, sigma)\n",
    "X_Hydro_detrend             = FUNC.gaussian_smooth(results_X_CS_Hydro, sigma)\n",
    "X_MorphoTOT_detrend         = FUNC.gaussian_smooth(results_X_CS_MorphoTOT, sigma)\n",
    "X_MorphoXshore_detrend      = FUNC.gaussian_smooth(results_X_CS_MorphoXshore, sigma)\n",
    "X_MorphoLST_detrend         = FUNC.gaussian_smooth(results_X_CS_MorphoLST,sigma)\n",
    "\n",
    "X_val_detrend               = FUNC.gaussian_smooth(Xshores_val, sigma)\n",
    "\n",
    "dx_Hydro_detrend            = FUNC.gaussian_smooth(results_dx_CS_Hydro, sigma)\n",
    "dx_MorphoLST_detrend        = FUNC.gaussian_smooth(results_dx_CS_MorphoLST, sigma)\n",
    "dx_MorphoXshore_detrend     = FUNC.gaussian_smooth(results_dx_CS_MorphoXshore, sigma)\n",
    "dx_MorphoTOT_detrend        = FUNC.gaussian_smooth(results_dx_CS_MorphoTOT, sigma)\n",
    "dx_TOTAL_detrend            = FUNC.gaussian_smooth(results_dx_CS_TOTAL,sigma)\n",
    "\n",
    "SLA_detrend                 = FUNC.gaussian_smooth(SLA[:,results_index],sigma)\n",
    "DAC_detrend                 = FUNC.gaussian_smooth(DAC[:,results_index],sigma)\n",
    "SU_detrend                  = FUNC.gaussian_smooth(SU[:,results_index],sigma)\n",
    "DKAMP_detrend               = FUNC.gaussian_smooth(results_dKAMP,sigma)\n",
    "QrivD_detrend               = FUNC.gaussian_smooth(QrivD[:,results_index],sigma)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# b. LINEAR DETREND\n",
    "X_MorphoLST_detrend_linear    = np.apply_along_axis(detrend_linear,0,X_MorphoLST_detrend)\n",
    "X_Hydro_detrend_linear        = np.apply_along_axis(detrend_linear,0,X_Hydro_detrend)\n",
    "X_MorphoXshore_detrend_linear = np.apply_along_axis(detrend_linear,0,X_MorphoXshore_detrend)\n",
    "X_MorphoTOT_detrend_linear    = np.apply_along_axis(detrend_linear,0,X_MorphoTOT_detrend)\n",
    "X_TOTAL_detrend_linear        = np.apply_along_axis(detrend_linear,0,X_TOTAL_detrend)\n",
    "X_val_detrend_global          = np.apply_along_axis(detrend_linear,0,Xshores_val)\n",
    "\n",
    "\n",
    "dx_Hydro_detrend_linear       = np.apply_along_axis(detrend_linear,0,dx_Hydro_detrend)\n",
    "dx_MorphoLST_detrend_linear   = np.apply_along_axis(detrend_linear,0,dx_MorphoLST_detrend)\n",
    "dx_MorphoXshore_detrend_linear= np.apply_along_axis(detrend_linear,0,dx_MorphoXshore_detrend)\n",
    "dx_MorphoTOT_detrend_linear   = np.apply_along_axis(detrend_linear,0,dx_MorphoTOT_detrend)\n",
    "dx_TOTAL_detrend_linear       = np.apply_along_axis(detrend_linear,0,dx_TOTAL_detrend)\n",
    "\n",
    "\n",
    "SLA_detrend_linear            = np.apply_along_axis(detrend_linear,0,SLA_detrend)\n",
    "DAC_detrend_linear            = np.apply_along_axis(detrend_linear,0,DAC_detrend)\n",
    "SU_detrend_linear             = np.apply_along_axis(detrend_linear,0,SU_detrend)\n",
    "DKAMP_detrend_linear          = np.apply_along_axis(detrend_linear,0,DKAMP_detrend)\n",
    "QrivD_detrend_linear          = np.apply_along_axis(detrend_linear,0,QrivD_detrend)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
