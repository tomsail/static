{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import json\n",
    "import io\n",
    "import holoviews as hv\n",
    "import geopandas as gp\n",
    "import searvey\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL for the API\n",
    "sl_api  = \"https://webcritech.jrc.ec.europa.eu/SeaLevelsDb/api/Group/\"\n",
    "tad_api = \"https://webcritech.jrc.ec.europa.eu/TAD_server/api/Groups/Get\"\n",
    "\n",
    "api_device = \"https://webcritech.jrc.ec.europa.eu/api/Device/\"\n",
    "\n",
    "# Fetch the list of providers\n",
    "sl_response = requests.get(sl_api)\n",
    "tad_response = requests.get(tad_api)\n",
    "sl_data = json.loads(sl_response.text)  # Parse the JSON response\n",
    "tad_data = json.loads(tad_response.text)  # Parse the JSON response\n",
    "sl_data;tad_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SeaLevelDB stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold all station data\n",
    "SL_data = []\n",
    "\n",
    "# Loop through the list of providers and fetch their stations\n",
    "for provider in sl_data:\n",
    "    provider_name = provider['Name']\n",
    "    stations_url = sl_api + provider_name + \"/Devices\"\n",
    "    stations_response = requests.get(stations_url)\n",
    "    stations_data = json.loads(stations_response.text)  # Parse the JSON response\n",
    "    # Loop through each station and extract data\n",
    "    for device in stations_data:\n",
    "        station_data = {\n",
    "            'Provider': provider_name,\n",
    "            'Id': device['Id'],\n",
    "            'Name': device['Name'],\n",
    "            'lat': device['Lat'],\n",
    "            'lon': device['Lon'],\n",
    "            'LastAccessStatus': device['CurrentStatus']['LastAccessStatus'],\n",
    "            'LastDate': device['CurrentStatus']['LastDate'],\n",
    "            'State': device['CurrentStatus']['State'],\n",
    "            'SyncStatus': device['CurrentStatus']['SyncStatus'],\n",
    "            'FileType': device['FileType'],\n",
    "            'GroupId': device['GroupId'],\n",
    "            'MovAvgNp': device['MovAvgNp'],\n",
    "            'Notes': device.get('Notes'),  # Use .get() to handle missing keys\n",
    "            'Source': device['Source']\n",
    "            # Add other fields as necessary\n",
    "        }\n",
    "        SL_data.append(station_data)\n",
    "SL_df = pd.DataFrame(SL_data)\n",
    "SL_df\n",
    "SL_df.to_csv('SeaLevelDb_stations.csv')\n",
    "SL_df.groupby(['Provider','State']).count()[['Id']].hvplot.bar(\n",
    "    rot = 90,\n",
    "    logy = True,\n",
    "    ylim = [0.5, 2000], \n",
    "    grid = True\n",
    ").opts(\n",
    "    width = 1200,\n",
    "    height = 800,\n",
    "    title = \"SeaLevelDb data availability\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAD_data Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAD_data = []\n",
    "# Loop through the list of providers and fetch their stations\n",
    "for provider in tad_data:\n",
    "    provider_name = provider['Name']\n",
    "    stations_url = f\"https://webcritech.jrc.ec.europa.eu/TAD_server/api/Groups/GetGeoJSON?group={provider_name}&maxLatency=10000000\"\n",
    "    stations_response = requests.get(stations_url)\n",
    "    stations_data = json.loads(stations_response.text)  # Parse the JSON response\n",
    "    if isinstance(stations_data, dict): stations_data = [stations_data]\n",
    "    # Loop through each station and extract data\n",
    "    if len(stations_data)>0:\n",
    "        for device in stations_data[0]['features']:\n",
    "            properties = device.get('properties', {})\n",
    "            geometry = device.get('geometry', {})\n",
    "            coordinates = geometry.get('coordinates', [None, None])\n",
    "            latency = properties.get('Latency', {}).get('Literal')\n",
    "            last_data_date_str = properties.get('LastData', {}).get('Date')\n",
    "            last_data_date = pd.Timestamp(last_data_date_str)\n",
    "            \n",
    "            # Determine if the measurement is within the last week\n",
    "            state = \"active\" if last_data_date and (pd.Timestamp.now() - last_data_date) <= pd.Timedelta(days=7) else \"inactive\"\n",
    "\n",
    "            station_data = {\n",
    "                'Provider': properties.get('Provider'),\n",
    "                'Id': device.get('id'),\n",
    "                'Name': properties.get('Name'),\n",
    "                'lat': coordinates[1],\n",
    "                'lon': coordinates[0],\n",
    "                'LastAccessStatus': properties.get('LastData', {}).get('Date'),\n",
    "                'LastDate': last_data_date,\n",
    "                'SyncStatus': latency,\n",
    "                'State': state,\n",
    "                'FileType': None,  # Update this if there is a corresponding field in the new data\n",
    "                'GroupId': None,  # Update this if there is a corresponding field in the new data\n",
    "                'MovAvgNp': None,  # Update this if there is a corresponding field in the new data\n",
    "                'Notes': properties.get('Notes'),  # Use .get() to handle missing keys\n",
    "                'Source': None\n",
    "                # Add other fields as necessary\n",
    "            }\n",
    "            TAD_data.append(station_data)\n",
    "TAD_df = pd.DataFrame(TAD_data)\n",
    "TAD_df\n",
    "TAD_df.to_csv('TAD_stations.csv')\n",
    "TAD_df.groupby(['Provider','State']).count()[['Id']].hvplot.bar(\n",
    "    rot = 90,\n",
    "    logy = True,\n",
    "    ylim = [0.5, 2000], \n",
    "    grid = True\n",
    ").opts(\n",
    "    width = 1600,\n",
    "    height = 800,\n",
    "    title = \"SeaLevelDb data availability\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference stations already in use in Seareport: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stofs2d_meta():\n",
    "    stofs2d = pd.read_csv(\n",
    "        \"https://polar.ncep.noaa.gov/stofs/data/stofs_2d_glo_elev_stat_v2_1_0\",\n",
    "        names=[\"coords\", \"name\"],\n",
    "        sep=\"!\",\n",
    "        header=None,\n",
    "        skiprows=1\n",
    "    )\n",
    "    stofs2d = stofs2d.assign(\n",
    "        lon=stofs2d.coords.str.split(\"\\t\", n=1).str[0].astype(float),\n",
    "        lat=stofs2d.coords.str.strip().str.rsplit(\"\\t\", n=1).str[1].astype(float),\n",
    "        stofs2d_name=stofs2d.name.str.strip(),\n",
    "    ).drop(columns=[\"coords\", \"name\"])\n",
    "    return stofs2d\n",
    "\n",
    "\n",
    "def get_ioc_meta() -> gp.GeoDataFrame:\n",
    "    meta_web = searvey.get_ioc_stations().drop(columns=[\"lon\", \"lat\"])\n",
    "    meta_api = (\n",
    "        pd.read_json(\n",
    "            \"http://www.ioc-sealevelmonitoring.org/service.php?query=stationlist&showall=all\"\n",
    "        )\n",
    "        .drop_duplicates()\n",
    "        .drop(columns=[\"lon\", \"lat\"])\n",
    "        .rename(columns={\"Code\": \"ioc_code\", \"Lon\": \"lon\", \"Lat\": \"lat\"})\n",
    "    )\n",
    "    merged = pd.merge(\n",
    "        meta_web,\n",
    "        meta_api[[\"ioc_code\", \"lon\", \"lat\"]].drop_duplicates(),\n",
    "        on=[\"ioc_code\"],\n",
    "    )\n",
    "    return merged\n",
    "\n",
    "def merge_ioc_and_stofs(ioc: pd.DataFrame, stofs2d: pd.DataFrame) -> pd.DataFrame:\n",
    "    stations = pd.concat((ioc, stofs2d), ignore_index=True)\n",
    "    stations = stations.assign(unique_id=stations.ioc_code.combine_first(stations.stofs2d_name))\n",
    "    return stations\n",
    "\n",
    "ioc = get_ioc_meta()\n",
    "stofs2d = get_stofs2d_meta()\n",
    "stations = merge_ioc_and_stofs(ioc=ioc, stofs2d=stofs2d)\n",
    "stations['is_sat'] = stations.unique_id.str.contains('SA')\n",
    "stations['source'] = \"stofs\"\n",
    "stations['source'][~stations.ioc_code.isna()] = \"ioc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot0 = stations.drop(columns='geometry')[~stations['is_sat']][stations.source == 'stofs'].hvplot.points(\n",
    "    x = 'lon',\n",
    "    y='lat',\n",
    "    c = 'orange',\n",
    "    s=100,\n",
    "    line_color = 'white',\n",
    "    geo = True,\n",
    ")\n",
    "plot1 = stations.drop(columns='geometry')[~stations['is_sat']][stations.source == 'ioc'].hvplot.points(\n",
    "    x = 'lon',\n",
    "    y='lat',\n",
    "    c = 'r',\n",
    "    s=100,\n",
    "    line_color = 'white',\n",
    "    geo = True,\n",
    ")\n",
    "plot2 = pd.concat([SL_df,TAD_df]).hvplot.points(\n",
    "    x = 'lon',\n",
    "    y='lat',\n",
    "    c = 'Provider',\n",
    "    line_color = 'k',\n",
    "    cmap = 'glasbey',\n",
    "    geo = True,\n",
    "    tiles=\"OSM\",\n",
    ")\n",
    "\n",
    "(plot0 * plot1 * plot2).opts(\n",
    "    width = 1400,\n",
    "    height = 1070\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare TD UNESCO with Seareport stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot0 = stations.drop(columns='geometry')[~stations['is_sat']][stations.source == 'stofs'].hvplot.points(\n",
    "    x = 'lon',\n",
    "    y='lat',\n",
    "    c = 'orange',\n",
    "    s=100,\n",
    "    line_color = 'white',\n",
    "    geo = True,\n",
    ")\n",
    "plot1 = stations.drop(columns='geometry')[~stations['is_sat']][stations.source == 'ioc'].hvplot.points(\n",
    "    x = 'lon',\n",
    "    y='lat',\n",
    "    c = 'r',\n",
    "    s=100,\n",
    "    line_color = 'white',\n",
    "    geo = True,\n",
    ")\n",
    "plot2 = SL_df[SL_df.Provider.isin(['TD UNESCO'])].hvplot.points(\n",
    "    x = 'lon',\n",
    "    y='lat',\n",
    "    c = 'Provider',\n",
    "    line_color = 'k',\n",
    "    cmap = 'glasbey',\n",
    "    geo = True,\n",
    "    tiles=\"OSM\",\n",
    ")\n",
    "\n",
    "(plot0 * plot1 * plot2).opts(\n",
    "    width = 1400,\n",
    "    height = 1070\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations = pd.concat([SL_df,TAD_df])\n",
    "all_stations['period_inactive'] = all_stations.apply(lambda x:(pd.Timestamp.now() - pd.Timestamp(x['LastDate']).tz_localize(None)).total_seconds()/3600/24/365.25, axis = 1)\n",
    "\n",
    "# Updated code using .loc to avoid SettingWithCopyWarning\n",
    "all_stations.loc[all_stations.period_inactive <= 0, 'period_inactive'] = 0\n",
    "all_stations.loc[all_stations.period_inactive >= 10, 'period_inactive'] = 10\n",
    "\n",
    "# Then you can describe the data\n",
    "all_stations.period_inactive.hvplot.hist().opts(title = \"years inactive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations.to_csv('TAD_SLDB_stations.csv')\n",
    "all_stations.hvplot.points(\n",
    "    x = 'lon',\n",
    "    y='lat',\n",
    "    c = 'period_inactive',\n",
    "    line_color = \"k\",\n",
    "    line_width = 0.25,\n",
    "    cmap = 'fire_r',\n",
    "    S = 100,\n",
    "    geo = True,\n",
    "    tiles=\"OSM\",\n",
    ").opts(title = \"years inactive\", width = 1400, height=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations['LastDate_pd'] =  all_stations.apply(lambda x:pd.Timestamp(x['LastDate']).tz_localize(None), axis = 1)\n",
    "all_stations['LastDate_pd'].hvplot.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of station seem to have stopped in January 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data (not finished yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searvey.multi import multithread\n",
    "\n",
    "# rate_limit \n",
    "def fetch_SeaLevelDb_station(tmin: pd.Timestamp, tmax: pd.Timestamp, id: int, NSTEPS = 10000000):\n",
    "    url = f\"https://webcritech.jrc.ec.europa.eu/SeaLevelsDb/api/Device/{id}/Data?tMin={tmin.strftime('%Y-%m-%d')}&tMax={tmax.strftime('%Y-%m-%d')}&nPts={NSTEPS}&field=level&mode=CSV\"\n",
    "    stations_response = requests.get(url)\n",
    "    if stations_response.ok:\n",
    "        data = json.loads(stations_response.text)  # Use `loads` instead of `load`\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Error: {stations_response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def fetch_TAD_station(tmin: pd.Timestamp, tmax: pd.Timestamp, id: int, NSTEPS = 10000000): \n",
    "    url = f\"https://webcritech.jrc.ec.europa.eu/TAD_server/api/Data/Get/{id}?tMin={tmin.strftime('%Y-%m-%d')}&tMax={tmax.strftime('%Y-%m-%d')}&nRec={NSTEPS}&mode=CSV\"\n",
    "    stations_response = requests.get(url)\n",
    "    if stations_response.ok:\n",
    "        data = io.StringIO(stations_response.text)  # Create a text stream object\n",
    "        df = pd.read_csv(data)  # Read the DataFrame from the text stream\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Error: {stations_response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_TAD_stations(df:pd.DataFrame, device_var: str):\n",
    "    for s, station in df.iterrows():\n",
    "        print(s, station)\n",
    "        1/0\n",
    "\n",
    "\n",
    "def get_SLDB_stations(df:pd.DataFrame, device_var: str):\n",
    "    for s, station in df.iloc[::-1].iterrows():\n",
    "        print(station)\n",
    "        func_kwargs = []\n",
    "        for tstep in pd.date_range(pd.Timestamp(2020, 1, 1), station.LastDate, freq='MS'):\n",
    "            tmin = tstep\n",
    "            tmax = tstep + relativedelta(months=+1)\n",
    "            func_kwargs.append(\n",
    "                dict(\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    Device=station[device_var],\n",
    "                ),\n",
    "            )\n",
    "        results = multithread(\n",
    "            func=fetch_SeaLevelDb_station,\n",
    "            func_kwargs=func_kwargs,\n",
    "            n_workers=10,\n",
    "            print_exceptions=False,\n",
    "            disable_progress_bar=False,\n",
    "        )   \n",
    "        for result in results:\n",
    "            if result.result is not None:\n",
    "                df = result.result\n",
    "                print(df)\n",
    "        1/0\n",
    "\n",
    "get_SLDB_stations(SL_df, \"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Device = 94\n",
    "url = f\"https://webcritech.jrc.ec.europa.eu/TAD_server/api/Data/Get/{Device}?tMin=2024-08-01&tMax=2024-09-01&nRec={10000000}&mode=CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_response = requests.get(url)\n",
    "data = io.StringIO(stations_response.text)  # Create a text stream object\n",
    "df = pd.read_csv(data)  # Read the DataFrame from the text stream\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hvplot.line( y='Lev RAD (m)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
