{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the methodology for: \n",
    " 1. choosing the best IOC candidates for storm surge validation purposes\n",
    "\n",
    "an edit of this notebook will be done for: \n",
    "\n",
    " 2. the data availability\n",
    " 3. the data quality \n",
    "of IOC candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import searvey\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sklearn.neighbors\n",
    "import xarray as xr\n",
    "import hvplot.pandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_oceans = gp.read_file(\"https://gist.github.com/tomsail/2fa52d9667312b586e7d3baee123b57b/raw/23929561eaa8aa76376580a7df300c4e3eb2e509/world_maritime_sectors.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOC_CLEANUP = \"ioc_cleanup_2023.csv\"\n",
    "ioc_cleanup = pd.read_csv(IOC_CLEANUP, index_col=0).rename(columns={\"longitude\": 'lon', \"latitude\": 'lat', \"Station_Name\":\"location\",\"Country\":\"country\"})\n",
    "(   world_oceans.hvplot(c='ocean',geo=True).opts(cmap='tab20c') * \n",
    "    ioc_cleanup.hvplot.points(x=\"lon\",y=\"lat\",c='k', s= 40,geo=True,coastline=True)\n",
    " ).opts(height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our experience with [skill-panel-demo](https://github.com/seareport/skill-panel-demo) got us the to following conclusion:\n",
    "\n",
    "The previous set of stations from `ioc_cleanup` is not sufficient. We now need to have: \n",
    " * more stations to compare with models\n",
    " * more time coverage\n",
    "\n",
    "We want to have a maximum of stations that correspond with STOFS2D output locations. as we  want to compare: \n",
    " **IOC observations** vs **our model** vs **STOFS2D** output locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The latest STOFS2D locations output locations (for STOFS2D version 2.1.0) are: \n",
    "def get_stofs():\n",
    "    mycols = [str(i) for i in range(6)] # we expect 17 cols max in that file\n",
    "    stof2d = pd.read_csv(\n",
    "        \"https://polar.ncep.noaa.gov/stofs/data/stofs_2d_glo_elev_stat_v2_1_0\",\n",
    "        names=mycols, \n",
    "        sep=\"\\t+|!\", \n",
    "        header=None, \n",
    "        skiprows=1\n",
    "    )\n",
    "    stof2d['Info'] = stof2d.apply(lambda row: ' '.join(filter(None, row[2:])), axis=1)\n",
    "    stof2d['ID'] = stof2d['Info'].apply(lambda x: ' '.join(x.split()[:3]))\n",
    "    stof2d['Info'] = stof2d.apply(lambda row: row['Info'].replace(row['ID'], '').strip(), axis=1)\n",
    "    stof2d = stof2d.drop(columns=[\"2\", \"3\", \"4\", \"5\"])\n",
    "    stof2d.rename(columns={\"0\": 'lon', \"1\": 'lat'}, inplace=True)\n",
    "    return stof2d\n",
    "\n",
    "stofs = get_stofs()\n",
    "stofs.hvplot.points(geo=True,coastline=True).opts(height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A caveat is that the 1D output files evolve over time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stofs1 = xr.open_dataset(\"stofs2d/20220912_stofs_2d_glo.t12z.points.swl.nc\")\n",
    "stofs2 = xr.open_dataset(\"stofs2d/20231010_stofs_2d_glo.t00z.points.swl.nc\")\n",
    "stofs3 = xr.open_dataset(\"stofs2d/20241229_stofs_2d_glo.t00z.points.swl.nc\")\n",
    "#SEE APPENDIX FOR DOWNLOADING STOFS2D DATA\n",
    "\n",
    "stofs_2022 = stofs[stofs.ID.isin([' '.join(s.decode(\"utf-8\").strip().split()[:3]) for s in stofs1.station_name.values])];len(stofs_2022)\n",
    "stofs_2023 = stofs[stofs.ID.isin([' '.join(s.decode(\"utf-8\").strip().split()[:3]) for s in stofs2.station_name.values])];len(stofs_2023)\n",
    "stofs_2024 = stofs[stofs.ID.isin([' '.join(s.decode(\"utf-8\").strip().split()[:3]) for s in stofs3.station_name.values])];len(stofs_2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "luckily the new stations were appended at the end of the file. So this will be easier to concatenate data between all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stofs_2022[:557].equals(stofs_2023[:557])\n",
    "stofs_2022[:557].equals(stofs_2024[:557])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compare model storm surge with observation. We use IOC tide stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta() -> gp.GeoDataFrame:\n",
    "    meta_web = searvey.get_ioc_stations().drop(columns=[\"lon\", \"lat\"])\n",
    "    meta_api = (\n",
    "        pd.read_json(\n",
    "            \"http://www.ioc-sealevelmonitoring.org/service.php?query=stationlist&showall=all\"\n",
    "        )\n",
    "        .drop_duplicates()\n",
    "        .drop(columns=[\"lon\", \"lat\"])\n",
    "        .rename(columns={\"Code\": \"ioc_code\", \"Lon\": \"lon\", \"Lat\": \"lat\"})\n",
    "    )\n",
    "    merged = pd.merge(\n",
    "        meta_web,\n",
    "        meta_api[[\"ioc_code\", \"lon\", \"lat\"]].drop_duplicates(),\n",
    "        on=[\"ioc_code\"],\n",
    "    )\n",
    "    return merged.drop(columns=[\"geometry\"])\n",
    "ioc_ = get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have established a database for clean IOC data between 2022 and 2023 (see 1st plot), we'll use it as a reference: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stofs_plot = stofs_2022.hvplot.scatter(x= \"lon\", y=\"lat\", hover_cols = \"ID\", s=130, c='lightgrey', label = 'STOFS 2022 output stations')\n",
    "stofs_plot1 = stofs_2023.hvplot.scatter(x=\"lon\", y=\"lat\", hover_cols = \"ID\", s=150, c='grey', label = 'STOFS 2023 output stations')\n",
    "stofs_plot2 = stofs_2024.hvplot.scatter(x=\"lon\", y=\"lat\", hover_cols = \"ID\", s=200, c='k', label = 'STOFS 2024 output stations')\n",
    "ioc_plot = ioc_.hvplot.scatter(x=\"lon\", y=\"lat\",hover_cols = \"ioc_code\", s= 30 , c = 'y', label = 'all IOC stations')\n",
    "ioc_cleanup_plot = ioc_cleanup.hvplot.scatter(coastline=True,x=\"lon\", y=\"lat\",s = 80, c='r', label = \"stations cleaned for 2022-2023\")\n",
    "\n",
    "(stofs_plot2 * stofs_plot1 * stofs_plot * ioc_cleanup_plot* ioc_plot).opts(width = 1300, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We graphically detected all stations not already used in `ioc_cleanup` and corresponding with STOFS2D output locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_to_add = [\"juan\", \"sanf\", \"anto\", \"ptmo\", \"valp\", \"ferg\", \"ambon\", \"bitu\", \"saum\", \"sho2\", \"ushu\", \n",
    "                  \"espr\", \"gamb\", \"riki\", \"prud\", \"vald\", \"cord\", \"paak\", \"dsea\", \"ketc\", \"june\", \"skag\", \"sewa\", \"anch\", \"niki\", \"seld\", \"kodi\", \"alak\", \n",
    "                  \"dshu\", \"dkod\", \"nome\", \"adak\", \"niko\", \"dchu\", \"midx\", \"fren\", \"sthl\", \"ascen\", \"jask\", \"chab\", \"kara\", \"musc\", \n",
    "                  \"masi\", \"mais\", \"kerg\", \"syow\", \"ver1\", \"vern\", \"wait\", \"stpa\", \"sala\", \"tara\", \"marsh\", \"kwaj\", \"wake\", \"fong\", \n",
    "                  \"solo\", \"vanu\", \"numbo\", \"numb2\", \"levu\", \"wlgt\", \"jack\", \"hako\", \"abas\", \"ofun\", \"mera\", \"toya\", \"nawi\", \"brpt\", \"heeia\", \n",
    "                  \"moku\", \"mane\", \"john\", \"plmy\", \"xmas\", \"penr\", \"hiva\", \"pape\", \"raro\", \"pago\", \"pagx\", \"east\", \"garc\", \"Male2\", \"ganm\", \"male\", \"hani\", \n",
    "                  \"mini\", \"coch\", \"vish\", \"chtt\", \"sitt\", \"moul\", \"ptbl\", \"komi\", \"kota\", \"lank\", \"ms001\", \"sab2\", \"saba\", \"vung\", \"quin\", \n",
    "                  \"quar\", \"curri\", \"subi\", \"mani\", \"luba\", \"lega\", \"tkao\", \"tkee\", \"chij\", \"mins\", \"saip\", \"mala\", \"chuu\", \"kapi\", \"deke\", \"naur\", \"nauu\", \n",
    "                  \"dumo\", \"espe\", \"porl\", \"hill\", \"waik\", \"lemba\", \"beno\", \"prgi\", \"prig\", \"cili\", \"cila\", \"tjls\", \"chrs\", \"ffcj\", \"cocb\", \"telu\", \"sibo\", \n",
    "                  \"sib2\", \"tanjo\", \"bupo\", \"padn\", \"pada\", \"fpga\", \"winc\", \"wbnc\", \"oinc\", \"kpva\", \"leva\", \"simd\", \"wsdc\", \"cbmd\", \"ocmd\", \"cmnj\", \"phap\", \n",
    "                  \"mhpa\", \"btny\", \"shnj\", \"mony\", \"ptme\", \"cwme\", \"epme\", \"hali\", \"nain\", \"nuk1\", \"nuuk\", \"qaqo\", \"reyk\", \"scor\", \"rptx\", \"cctx\", \"pitx\", \n",
    "                  \"pric\", \"ftfr\", \"rose\", \"barb\", \"stcr\", \"lame\", \"isab\", \"vieq\", \"yobu\", \"yabu\", \"faja\", \"sanj\", \"arac\", \"maya\", \"magi\", \"penu\", \"mona\", \n",
    "                  \"ptpr\", \"ptpl\", \"sama\", \"bull\", \"elpo\", \"limon\", \"quepo\", \"sana\", \"acaj\", \"acap\", \"acya\", \"manz\", \"mnza\", \"cabo\", \"fort\", \"call\", \"lobos\", \n",
    "                  \"tala\", \"lali\", \"vkfl\", \"nafl\", \"fmfl\", \"spfl\", \"pnfl\", \"pbfl\", \"apfl\", \"tpfl\", \"fbfl\", \"moal\", \"wlms\", \"psla\", \"gila\", \"pfla\", \"ncla\", \n",
    "                  \"apla\", \"eila\", \"cpla\", \"sptx\", \"gptx\", \"fptx\", \"bres\", \"sthm\", \"casc\", \"gibr\", \"ceut\", \"mars\", \"TR22\", \"gvd9\", \"alex\", \"palm\", \"pdas\", \n",
    "                  \"plus\", \"dakar\", \"tako\", \"tkdi\", \"lagos\", \"pntn\", \"sitin\", \"walvi\", \"prte\", \"durb\", \"pemba\", \"mtwa\", \"momb\", \"lamu\", \"pmon\", \"aric\", \"mata\", \n",
    "                  \"plat\", \"salv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some station can be declined in different names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_stations = []\n",
    "all_ioc = ioc_.ioc_code.values\n",
    "for stat in station_to_add:\n",
    "    if any(stat in station for station in all_ioc):\n",
    "        for station in all_ioc:\n",
    "            if stat in station:\n",
    "                possible_stations.append(station)\n",
    "ioc_to_add = ioc_[ioc_.ioc_code.isin(possible_stations)]\n",
    "ioc_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stofs_plot =  stofs_2022.hvplot.scatter(x= \"lon\", y=\"lat\", hover_cols = \"ID\", s=130, c='lightgrey', label = 'STOFS 2022 output stations')\n",
    "stofs_plot1 = stofs_2023.hvplot.scatter(x=\"lon\", y=\"lat\", hover_cols = \"ID\", s=150, c='grey', label = 'STOFS 2023 output stations')\n",
    "stofs_plot2 = stofs_2024.hvplot.scatter(x=\"lon\", y=\"lat\", hover_cols = \"ID\", s=200, c='k', label = 'STOFS 2024 output stations')\n",
    "ioc_cleanup_plot = ioc_cleanup.hvplot.scatter(x=\"lon\", y=\"lat\",hover_cols = \"ioc_code\",s = 90, c='r',label = 'stations already cleaned for 2022-2023')\n",
    "ioc_to_add_plot = ioc_to_add.hvplot.scatter(coastline=True,x=\"lon\", y=\"lat\",s = 90, c = 'g', label = 'stations to be added')\n",
    "\n",
    "(stofs_plot2 * stofs_plot1 * stofs_plot * ioc_to_add_plot * ioc_cleanup_plot).opts(width = 1400, height = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the 2024 IOC cleanup database is the red + green points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ioc_cleanup_2024 = pd.concat([ioc_cleanup,ioc_to_add])\n",
    "ioc_cleanup_2024\n",
    "ioc_cleanup_2024.to_csv(\"ioc_cleanup_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_nodes(\n",
    "    mesh_nodes: pd.DataFrame,\n",
    "    points: pd.DataFrame,\n",
    "    metric: str = \"haversine\",\n",
    "    earth_radius = 6371000,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculate the mesh nodes that are nearest to the specified `points`.\n",
    "    Both `mesh_nodes` and `points` must be `pandas.DataFrames` that have\n",
    "    columns named `lon` and `lat` and the coords must be in EPSG:4326.\n",
    "    Returns the `points` DataFrame after adding these extra columns:\n",
    "    - `mesh_index` which is the index of the node in the `hgrid.gr3` file\n",
    "    - `mesh_lon` which is the longitude of the nearest mesh node\n",
    "    - `mesh_lat` which is the latitude of the nearest mesh node\n",
    "    - `distance` which is the distance in meters between the point and the nearest mesh node\n",
    "    Examples:\n",
    "        >>> mesh_nodes = pd.DataFrame({\n",
    "        ...     \"lon\": [0, 10, 20],\n",
    "        ...     \"lat\": [0, 5, 0],\n",
    "        ... })\n",
    "        >>> points = pd.DataFrame({\n",
    "        ...     \"lon\": [1, 11, 21],\n",
    "        ...     \"lat\": [1, 4, 1],\n",
    "        ...     \"id\": [\"a\", \"b\", \"c\"],\n",
    "        ... })\n",
    "        >>> nearest_nodes = find_nearest_nodes(mesh_nodes, points)\n",
    "        >>> nearest_nodes\n",
    "           lon  lat id  mesh_index  mesh_lon  mesh_lat       distance\n",
    "        0    1    1  a           0         0         0  157249.381272\n",
    "        1   11    4  b           1        10         5  157010.162641\n",
    "        2   21    1  c           2        20         0  157249.381272\n",
    "    \"\"\"\n",
    "    # The only requirement is that both `mesh_nodes and `points` have `lon/lat` columns\n",
    "    tree = sklearn.neighbors.BallTree(\n",
    "        np.radians(mesh_nodes[[\"lat\", \"lon\"]]),\n",
    "        metric=metric,\n",
    "    )\n",
    "    distances, indices = tree.query(np.radians(points[[\"lat\", \"lon\"]].values))\n",
    "    closest_nodes = (\n",
    "        mesh_nodes\n",
    "        .rename(columns={\"lon\": \"mesh_lon\", \"lat\": \"mesh_lat\"})\n",
    "        .iloc[indices.flatten()]\n",
    "        .assign(distance=(distances.flatten() * earth_radius))\n",
    "        .reset_index(names=[\"mesh_index\"])\n",
    "    )\n",
    "\n",
    "    return pd.concat((points.reset_index(drop = True), closest_nodes), axis=\"columns\")\n",
    "\n",
    "# 2 - get STOFS\n",
    "nearest_nodes_2022 = find_nearest_nodes(stofs_2022, ioc_cleanup_2024[[\"lon\",\"lat\",\"ioc_code\",\"location\"]])\n",
    "nearest_nodes_2023 = find_nearest_nodes(stofs_2023, ioc_cleanup_2024[[\"lon\",\"lat\",\"ioc_code\",\"location\"]])\n",
    "nearest_nodes_2024 = find_nearest_nodes(stofs_2024, ioc_cleanup_2024[[\"lon\",\"lat\",\"ioc_code\",\"location\"]])\n",
    "nearest_nodes_2022 = nearest_nodes_2022[~nearest_nodes_2022.mesh_index.isna()]\n",
    "nearest_nodes_2023 = nearest_nodes_2023[~nearest_nodes_2023.mesh_index.isna()]\n",
    "nearest_nodes_2024 = nearest_nodes_2024[~nearest_nodes_2024.mesh_index.isna()]\n",
    "keep_nodes_2022 = nearest_nodes_2022[nearest_nodes_2022.distance < 5000]\n",
    "keep_nodes_2023 = nearest_nodes_2023[nearest_nodes_2023.distance < 5000]\n",
    "keep_nodes_2024 = nearest_nodes_2024[nearest_nodes_2024.distance < 5000]\n",
    "\n",
    "keep_nodes_2022.to_csv(\"keep_nodes_2022.csv\")\n",
    "keep_nodes_2023.to_csv(\"keep_nodes_2023.csv\")\n",
    "keep_nodes_2024.to_csv(\"keep_nodes_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "red are all the STOFS2D points to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = stofs_2022.hvplot.scatter(x=\"lon\", y=\"lat\", hover_cols = \"ID\", s=70, c='grey',line_color=\"lightgrey\", label = 'STOFS 2022 output stations')\n",
    "ip = ioc_cleanup_2024.hvplot.scatter(x=\"lon\", y=\"lat\",s = 10, c='k',coastline=True, label = 'IOC_CLEANUP 2022-2024')\n",
    "k2 = keep_nodes_2022.hvplot.scatter(x=\"lon\", y=\"lat\", c = 'red', s = 20,coastline=True, label = \"STOFS2D stations to be extracted\")\n",
    "\n",
    "# (world_oceans.hvplot(c='ocean',alpha= 0.9).opts(cmap='tab20c') * p2 * ip * k2 ).opts(width = 1100, height = 800)\n",
    "(world_oceans.hvplot(c='ocean',alpha= 0.9).opts(cmap='tab20c') * p2 * ip ).opts(width = 1500, height = 900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download IOC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i_s, station in ioc_cleanup_2024.iterrows():\n",
    "#     print(station.ioc_code)\n",
    "#     df = searvey.fetch_ioc_station(station.ioc_code, \"2022-01-01\", \"2024-12-31\")\n",
    "#     df.to_parquet(f\"data/{station.ioc_code}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import glob\n",
    "\n",
    "ioc_cleanup_2024['n_sensors'] = 0\n",
    "\n",
    "pattern = r\"data/([\\w\\d]+)\\.parquet\"\n",
    "stations = [re.search(pattern, path).group(1) for path in glob.glob(\"data/*parquet\")]\n",
    "f\"Total stations: {len(stations)}\"\n",
    "\n",
    "# get the stations with data\n",
    "keep_stations = []\n",
    "for station in sorted(stations): \n",
    "    df = pd.read_parquet(f\"data/{station}.parquet\")\n",
    "    if df.empty:\n",
    "        pass\n",
    "    else:\n",
    "        print(station, end=\"  \")\n",
    "        keep_stations.append(station)\n",
    "        if \"sw1\" in df.columns: df = df.drop(columns=[\"sw1\"])\n",
    "        if \"sw2\" in df.columns: df = df.drop(columns=[\"sw2\"])\n",
    "        if \"bat\" in df.columns: df = df.drop(columns=[\"bat\"])\n",
    "        print(list(df.columns))\n",
    "\n",
    "        ioc_cleanup_2024.loc[ioc_cleanup_2024.ioc_code == station, \"n_sensors\"] = len(df.columns)\n",
    "        # disregard sw1, sw2 and bat\n",
    "f\"Stations with data: {len(keep_stations)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ioc_cleanup_2024.n_sensors.hvplot.hist(bins=[-0.5,0.5,1.5,2.5,3.5,4.5,5.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ioc_cleanup_2024_with_data = ioc_cleanup_2024[ioc_cleanup_2024.ioc_code.isin(keep_stations)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store in separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_s, s in ioc_cleanup_2024_with_data.iterrows():\n",
    "    df = pd.read_parquet(f\"data/{s.ioc_code}.parquet\")\n",
    "    if \"sw1\" in df.columns: df = df.drop(columns=[\"sw1\"])\n",
    "    if \"sw2\" in df.columns: df = df.drop(columns=[\"sw2\"])\n",
    "    if \"bat\" in df.columns: df = df.drop(columns=[\"bat\"])\n",
    "    for sensor in df.columns:\n",
    "        ts = df[[sensor]]\n",
    "        ts.to_parquet(f\"raw/{s.ioc_code}_{sensor}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate data availabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"raw/([\\w\\d]+)\\.parquet\"\n",
    "stations_sensors = [re.search(pattern, path).group(1) for path in glob.glob(\"raw/*parquet\")]\n",
    "f\"Total individual recordings: {len(stations_sensors)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as T\n",
    "DETIDE_START = pd.Timestamp(2022,1,1)\n",
    "DETIDE_END = pd.Timestamp(2025,1,1)\n",
    "\n",
    "def calc_ratio(sr: pd.Series, period: pd.DatetimeIndex) -> float:\n",
    "    sr = sr[(period[0] <= sr.index) & (sr.index <= period[-1])]\n",
    "    return len(sr) / len(period)\n",
    "\n",
    "table = dict()\n",
    "for station_sensor in sorted(stations_sensors):\n",
    "    station, sensor = station_sensor.split('_')\n",
    "    df = pd.read_parquet(f\"raw/{station_sensor}.parquet\")\n",
    "    interval_value_counts = df.index.to_series().diff().value_counts()\n",
    "    main_interval_occurences = interval_value_counts.iloc[0]\n",
    "    main_interval = T.cast(pd.Timedelta, interval_value_counts.index[0])\n",
    "    detide_period = pd.date_range(DETIDE_START, DETIDE_END, freq=main_interval, inclusive=\"left\")\n",
    "    table[station_sensor] = dict()\n",
    "    item = ioc_cleanup_2024_with_data[ioc_cleanup_2024_with_data.ioc_code == station]\n",
    "    table[station_sensor][\"lon\"] = item.lon.values[0]\n",
    "    table[station_sensor][\"lat\"] = item.lat.values[0]\n",
    "    table[station_sensor][\"completeness\"] = calc_ratio(df, detide_period)\n",
    "    # redo per sensor \n",
    "\n",
    "stations_sensors_availability = pd.DataFrame(table).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_sensors_availability.describe()\n",
    "stations_sensors_availability.completeness.hvplot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_sensors_availability.hvplot.points(\n",
    "    x= \"lon\", y='lat', \n",
    "    hover_cols = ['index',\"completeness\" ],\n",
    "    color = \"completeness\", \n",
    "    geo=True,\n",
    "    s = 200\n",
    ").opts(\n",
    "    height = 800,\n",
    "    width = 1600, \n",
    "    cmap='colorwheel'\n",
    ") * k2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "searvey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
